[{"title":"一文弄懂区块链-以比特币为例","date":"2017-09-24T22:09:42.000Z","path":"2017/09/24/一文弄懂区块链-以比特币为例/","text":"【阅读时间】25min - 35min【内容简介】此文潜在面向群体是对区块链或比特币的运行原理完全不了解的人。所以会从用户需求的角度出发，一步一步发明区块链，在此之后的内容会涉及一些思考和技术上的原理延伸，可以选择性阅读 加密货币在一步一步发明发明比特币之前，有一些基本直观的认知需要阐明。 我们常说的比特币，是加密货币（Cryptocurrency）的一种，而加密货币实现去中心化的最关键的技术是区块链 有些地方可能把加密货币又称为数字货币（或称电子货币），但实际上，加密货币是数字货币的子集，同为子集的还有虚拟货币（如Q币），加密货币的称谓要更加专业 加密货币一定具有下列三个特点 去中心的清算 分布式的记账 离散化的支付 为了实现这些特点，需要使用到区块链技术。这里的区块链技术是一个很广义的范畴，它包含了密码学，算法等很多不同的内容，其中最精彩的点子，可算是工作量证明 = 共识信用了 一步一步发明比特币第一个用户需求 - 账本和电子签名的由来 第一个用户需求描述了中心化清算系统几个关键内容的由来，只对区块链感兴趣的读者可以跳过 经济体的蓬勃发展离不开交易。在交易过程中，人们早已发现使用一般等价物（如金银）十分麻烦，发明了纸币（北宋时代四川地区的纸币交子的清算体系），而最终，携带现金也很麻烦 这是第一个基本用户需求：摆脱现金进行交易带来的不方便 【解决办法】几个用户使用公共账本记录转账记录，月底结算，并且账本是公开的，每个人都可以修改，也就是说可以在上面添加行，如小明转账给小红10块钱 产生的问题1：身份问题在这个账本中我们无法确认条目小明和小红是否真实，可能出现欺诈现象 【解决办法】使用电子签名，即公钥 - 私钥对 过程解释为，小明使用自己的私钥（一个字符串）通过一连串的计算（加密函数）产生一个公钥（一串字符串），作为签名（一个字符串），验证过程是对签名和公钥进行一连串计算（验证函数）进行验证（输出为真/假，真为签名有效，证明这个公钥的确能证明这是小明的） 直观结果是，我们可以利用密码学的手段，保证小明的身份能被100%确认真实 但是这个解决方案有一个小漏洞：可以复制同一行信息来伪造交易记录，解决的办法是添加一个这笔交易独有的信息（比如时间戳） 产生的问题2：欠债跑路问题如果小明在此时账户上已经没有足够的余额进行支付，就会出现超支问题 【解决办法】添加余额记录，此时就不可避免的需要一个中间担保人（国家？信誉机构？银行？）为小明进行余额担保 一个大家都遵守的协议此时，现代金融体系的框架基本建立完毕，协议内容是 任何人都可以在账本上添加新行 固定时间间隔时用真金白银进行清算 只有有签名的交易是有效的 中间担保的人保证不可超支 此时发现一个很有趣的很容，这个比较严谨的协议有一个特点：如果所有人都按照这个协议来办事，我们可以永任何形式的东西来代替人民币了，换句话说，就是我根本不关心你在账本上添加的新行的交易内容是什么，可以是任何东西 利用这个提出需求再解决问题的过程，强化一个认知：货币 = 交易记录（账本），即货币的本质是交易记录，在这背后，有一个前提是，货币的另一个本质是一种共识，我们都信任的它有价值的共识 第二个用户需求：账本放在哪里？传统的（现在的）解决方案当时是，使用中心代理-银行，来存放账本 既然是第二个用户需求，那肯定就是因为现在的解决方案大家都不满意 核心需求：去中心化中心化的痛点大致可以说几点 银行效率低下，一笔跨国转账的等待时间较长 胖银行金融体系因部分准备金制度等等方便的规则，能抬升杠杆，产生金融泡沫，进一步诱发金融危机 私有财产神圣不可侵犯是精英与平民，剥削与被剥削者几个世纪以来讨论的核心 当然还有很多没有提到，总之，是一种一直饱受诟病的清算方式，此时，中本聪在2009年横空出世，他提出了一种全新的清算方法，并且真正解决的信用的问题！接下来就是真正的一步一步的发明比特币的过程了 如何实现分布记账（去中心化）为了去中心化，我们可以反其道而行之：每个用户保存账本，分布记账。用户产生一笔交易就讲这笔交易广播到到网络上所有的节点上，这样不就完美的去中心化了？ 广播模式分布式账本示意图 只要是明眼人都能发现，太天真的，这个方法行不通。可以，行不通，那就把行不通的原因总结出来 遇到问题，总结不可行的原因，寻找解决方案。这是整个人类不断前进的核心最小单位 问题核心如何让所有人都同意这个新账本？如何保持这些账本同步？有一笔交易发生时，如何让其他人都听到并相信这一笔交易呢？ 这些问题才是真正的核心：是否能在协议（办法，规则）中添加几行，找到办法，来决定是否接受交易，并确定交易顺序，使你可以放心的相信，世界上遵守同一协议的所有人手上的账本都和你的一模一样呢？（问题描述值得品读，只有抽象出问题才能更好的去寻找解决方案） ☆解决方案解决的思路是：哪个账本的计算工作量大，就信任哪个账本。换个角度来说是让交易欺诈和账本不一的情形的计算力成本高到不能接受甚至完全不可行 1、密码学：哈希函数哈希函数，输入可以是任意信息或者文件，输出是固定长度的比特串，例如256bit的1/0串，这个输出叫做这个信息的“哈希值”或者“摘要”（digest）。比如SHA256就是一个哈希函数 密码哈希函数的特点 密码哈希函数有几个特点 特点是输入值稍微变化后，结果就会有很大的不同，完全无法预测不同输入间的规律 逆向计算不可行，只能使用试错法（穷举法），解空间 $2^{256}$ 在每一个账本后添加一个特殊数字，对整个列表使用SHA256，我们要求这个特殊数字可以使得输出值的开头有30个零 寻找能使得输出前30位为0的特殊数字 根据之前说过SHA256的性质：输入变化输出不可预测，找到这个特殊数字唯一的办法就是穷举。换言之，你很容易就证明了他们进行了海量的计算。而这个特殊数字就叫做工作量证明（proof of work） 这就意味着，所有的工作量证明就对应了交易列表，如果你修改了一个交易，哪怕只有一点点，就会完全改变哈希值，就得重做工作量证明 修改后的重新计算 2、区块链 - 信用的共识的基石每一个小账本被称为区块，每一个不同的区块链协议（产生不同的加密货币）都会规定每一个区块所能包含的交易数量（1M or 2M it’s a question，当年中本聪谜一般的通过一次Clear up标记的Commit把相当重要的区块容量从32M调整为1M的年度大戏，关于区块容量也是一个值得讨论的问题），现在比特币每个区块的转账信息大约在2400笔左右 账本组成区块，区块构成链表，区块的头包含前一块的哈希值，这就是区块链 区块链的诞生 如此一来，任何人就不能随意修改其中的内容，或者交换顺序。如果你这么做，意味着你需要重新计算所有的特殊数字，这从概率上来说，是不可能的 区块链的诞生 允许世界上的每一个人建造区块。每一个新建区块的人（找到了这个特殊数字 - SHA256值有40个零）都能获得奖励，对于新建区块的这部分人（矿工）来说，以下几点需要注意 没有发送者信息，不需要签名 每一个新区块都会给整个币种增加新的虚拟（加密）货币 新建区块的过程又被称为“挖矿”：需要大量工作量并且可以向整个经济体注入新的货币 挖矿的工作是：接受交易信息，建造区块，把区块广播出去，然后得到新的钱作为奖励 对每个矿工来说，每个区块就像一个小彩票，所有人都在拼命快速猜数字，直到有一个幸运儿找到了一个特殊数字，使得整个区块的哈希值开头有许多个零，就能得到奖励。我记得有一个知乎答主给了一个形象的比喻，区块链就像一个拥有貌美如花女儿（区块）的国王，有很多的青年翘首以盼，而国王的方法是出了一道很难得题目让所有的青年计算（学习改变人生），谁算的快（在计算哈希值过程也可能是运气好）就能抱得美人归 对于想用这个系统来收付款的用户来说，他们不需要收听所有的交易，而只要收听矿工们广播出来的区块，然后更新到自己保存的区块链中就可以了 3、51%算力攻击问题这里有一个小漏洞，因为网络的延迟或者有人在篡改区块链等因素，你作为一个收听网络广播的用户，如果同时接受到两条不同的区块链怎么办？其中的交易信息发生了冲突 注：区块链本身就是最终的大账本，发生交易的唯一方法就是把你的交易加入到大账本上。具体来说，就是让矿工把你的交易记录加入它新挖到的区块中，并把这个区块链接到区块链上，链接的纽带，当然就是工作量证明 对于上面问题，用户的解决方案也比较简单：即，只保留最长的，也就是包含的工作量最大的那一条 用户保留最长的区块链 这里有一个Trick，即所谓信任工作量最大不仅仅是出【一道难题】，还通过等待多个区块的产生引入世界上所有矿工之间的博弈（吃瓜群众，坐看大戏，谁厉害我选谁，你们尽管斗） 个人观点：区块链的Idea最核心的创新就是从技术上把信任和贪婪画了等号。因为贪婪（希望去竞争建立区块的建立和交易费）所以信任（全网算力越大，用户越放心），这句话甚至带上了些许哲学和传奇的色彩 对于用户来说，是这样一种情景 如何更新本地区块链 其中的原因是，你可以假设Alice希望篡改一个交易信息，那么就意味着Alice需要不断的通过计算维护这个区块链了。也就是说每一次有新的区块链产生，Alice都需要不断的抢到这个彩票，理论上来说，他至少必须拥有全网51%以上的算力才能做到这一点，更多的，随着用户等待区块的增加，这个难度，幂次上升，在7-8个区块链产生后，概率上来讲，就是绝对信任 无穷大的篡改成本 此时 我们用数字签名保证了不能伪造交易记录 用区块链以及一些相应的规则保证了不能篡改其中的信息 这两点，就完成了：证明区块链的每一条交易记录都是可信的这一终极目标 总结 - 系统可行性分析只需要思考，我们如何才能在这个系统下骗人呢？ 如果你想篡改一笔不存在的交易记录，那么你必须比所有人都算的快，赢得这个彩票 但所有用户会继续收听其他矿工的广播 所以为了让所有用户继续相信这个伪造的区块 你必须投入自己所有的工作量，不断给篡改后的区块链分叉增添新的区块 记住：根据协议，所有用户会一直信任他所知道的最长的链 是的，你不可能持续的竞争过世界上所有的矿工 注意，作为一个用户，你不能立马相信你所听到的最新区块，而是应该等待多几个区块被创建过后，再确认这的确是世界所有人都在使用的区块链 发明过程中的关键点 电子签名 Digital Signatures 公共账本就是货币 The Ledger is the currency 去中心化 Decentralize 工作量证明 Proof of work 区块链 Block Chain 比特币技术到这里，已经发明了比特币，解决了去中心化的信任这一难题。只对比特币和区块链是什么这个问题的读者，希望大家可以在我的叙述中解决一些困惑，新技术，新点子，要拥抱它，使用它，必须先了解它。 我们知道区块链中记载的实体，对于比特币（加密货币）来说就是转账记录。但是，一个概念真正的跑起来，有甚多技术上，协议上的细节是需要追根问底的 接下里的部分主要探讨一些比特币具体实现方面的细节，如网络节点构成，比特币的计算难度系数，比特币总量的由来，比特币的缺陷等 比特币网络节点的构成比特币网络是一种点对点的数字现金系统，IP网络节点中每台机器都彼此对等，P2P网络不存在任何服务端、层级关系或者中心化服务。 节点类型与分工 一个全功能节点包含上述4个模块【钱包Wallet】【矿工Miner】【完整区块链full Block-chain database】【网络路由节点Network routing】 【网络路由节点】使得节点具有参与验证并传播交易与区块信息，发现监听并维持点对点的链接的能力 【完整区块链】具有此模块的节点被称为：全节点。它能够独自自主的校验所有交易，不需要任何其他信息。 【钱包】比特币的所有权是通过数字密钥、比特币地址和数字签名来确定的，用户自己保存私有密钥，钱包提供接入功能，余额查询等功能。有些节点仅仅保留区块链的一部分，通过一种”简易支付验证“（SPV Simplified Payment Verification）的方法来完成交易 【矿工】挖矿节点以相互竞争的方式创造新的区块。有一些挖矿节点也是全节点，可以独立挖矿；还有一些参与矿池挖矿的节点是轻量级节点，必须依赖矿池服务器维护全节点进行工作 拥有全部四个模块被称之为核心客户端（Bitcoin Core），除了这些主要节点类型外，还有一些服务器及节点运行其他协议，如特殊矿池挖矿协议、轻量级客户端访问协议。 下表为扩展比特币网络的不同节点类型 图示 名称 说明 独立矿工 具有完整区块链副本 完整区块链节点 此种节点有时有中继作用，不断收听网络广播，维护完整区块链 轻量(SPV)钱包 移动端，或者不想太过于笨重的桌面端，只需要进行交易广播操作 矿池协议服务器 将运行其他协议的节点，连接至P2P网络的网关路由器 挖矿节点 不具有区块链，但具备Stratum协议的节点或其他矿池挖矿协议的网络节点 轻量 Stratum 钱包 不具有区块链的钱包、运行Stratum协议的网络节点 扩展比特币网络要在全世界的网络中完成整个的交易，下图描述了一个扩展比特币网络，它包含了多重类型的节点、网关服务器、边缘路由器、钱包客户端以及它们互相连接所需要的各类协议 扩展比特币网络 除了江卓尔 知乎回答等优秀的知乎答主的回答，附参考文献出处：【1】文章中引用多个Gif的出处：比特币原理-3B1B，这也是让我真正弄懂比特币的一个视频，不得不说，外国人在让门外汉入行这件事上，领先了很多【2】一本入门教材。包含代码和实现，以及很多数据结构，具体实现方式的细节，如果想成为加密货币（区块链）开发者，这本书5星推荐：精通比特币【3】宋老师的鸿观125期 （需要优酷会员）【4】只能膜拜之的创世区块作者的论文：比特币白皮书","tags":[{"name":"BlockChain","slug":"BlockChain","permalink":"https://charlesliuyx.github.io/tags/BlockChain/"},{"name":"BTCoin","slug":"BTCoin","permalink":"https://charlesliuyx.github.io/tags/BTCoin/"}]},{"title":"【直观详解】拉格朗日乘法和KKT条件","date":"2017-09-20T17:49:49.000Z","path":"2017/09/20/拉格朗日乘法和KKT条件/","text":"【阅读时间】8min - 10mun【内容简介】直观的解读了什么是拉格朗日乘子法，以及如何求解拉格朗日方程，并且给出几个直观的例子，针对不等式约束解读了KKT条件的必要条件和充分条件 What &amp; Why拉格朗日乘法（Lagrange multiplier）是一种在最优化的问题中寻找多元函数在其变量受到一个或多个条件的相等约束时的求局部极值的方法。这种方法可以将一个有 n 个变量和 k 个约束条件的最优化问题转换为一个解有 n+k 个变量的方程组的解的问题 考虑一个最优化问题 $$ \\operatorname*{max}_{x,y} f(x,y) \\qquad s.t.\\;\\; g(x,y)=c $$ 为了求 $x$ 和 $y$ ，引入一个新的变量 $\\lambda$ 称为拉格朗日乘数，再引入朗格朗日函数的极值$$\\mathcal{L}(x,y,\\lambda)=f(x,y)-\\lambda \\cdot \\bigl( g(x,y) - c\\bigl) \\tag 1$$ 红线表示 $g(x,y) = c$ ，蓝线是 $f(x,y)$ 的等高线，所有箭头表示梯度下降最快的方向。图中红线与等高线相切的位置就是待求的极大值 How那么如何求这个极值点呢？ 单约束对(1)式直接求微分，并令其为零，计算出鞍点 $$ \\nabla_{x,y,\\lambda} \\mathcal{L}(x,y,\\lambda) = 0 $$ 有三个未知数，所以需要3个方程。求 $\\lambda$ 的偏微分有 $\\nabla_{\\lambda} \\mathcal{L}(x,y,\\lambda) = 0 \\implies g(x,y)=0$，则总结得 $$ \\nabla_{x,y,\\lambda} \\mathcal{L}(x,y,\\lambda) = 0 \\iff \\begin{cases} \\nabla_{x,y} f(x,y) = \\lambda \\nabla_{x,y} g(x,y) \\\\ g(x,y)=0 \\end{cases} $$ 例子1设一个具体的例子，我们需要求下列问题 $$ \\operatorname*{max}_{x,y} f(x,y) = x^2y \\qquad s.t.\\;\\; g(x,y): x^2+y^2-3=0 $$ 只有一个约束，使用一个乘子，设为 $\\lambda$，列出拉格朗日函数 $$ \\mathcal{L}(x,y,\\lambda)=f(x,y)-\\lambda \\cdot \\bigl( g(x,y) - c\\bigl) = x^2y + \\lambda(x^2+y^2-3) $$ 接下来求解上式，分别对三个待求量偏微分 $$ \\begin{align} \\nabla_{x,y,\\lambda} \\mathcal{L}(x,y,\\lambda) & = \\left( \\frac{\\partial \\mathcal{L}}{\\partial x},\\frac{\\partial \\mathcal{L}}{\\partial y},\\frac{\\partial \\mathcal{L}}{\\partial \\lambda}\\right)\\\\ & = (2xy + 2\\lambda x, x^2 + 2\\lambda y, x^2 + y^2 - 3) \\end{align} $$ 令偏微分分别等于0，得到 $$ \\nabla_{x,y,\\lambda} \\mathcal{L}(x,y,\\lambda) = 0 \\iff \\begin{cases} 2xy+2\\lambda x = 0 \\\\ x^2 + 2\\lambda y = 0 \\\\ x^2 + y^2 - 3 = 0 \\end{cases} \\iff \\begin{cases} x(y + \\lambda) = 0 & (i)\\\\ x^2 = -2\\lambda y & (ii)\\\\ x^2 +y^2 = 3 & (iii) \\end{cases} $$ 根据上式，我们可以解得 $\\mathcal{L}$: $$ (\\pm \\sqrt{2},1,-1 ); (\\pm \\sqrt{2},-1,1 );(0,\\pm \\sqrt{3},0) $$ 根据几个不同的解带入 $f(x,y)$ 得到，2，-2，0，也就是我们需要的最大值，最小值，对应的直观图像解释如下图所示（非常直观的展现约束和等高线的含义） 例子2关于拉格朗日乘子法的应用，有一个十分著名的：求离散概率分布 $p_1,p_2,\\cdots,p_n$ 的最大信息熵 $$ f(p1,p2,\\cdots,p_n) = - \\sum_{j=1}^n p_j log_2{p_j} \\\\ s.t. \\quad g(p1,p2,\\cdots,p_n) = \\sum_{k=1}^n p_k = 1 \\text{（概率和为1）} $$ 单约束问题，引入一个乘子 $\\lambda$ ，对于 $k \\in [1,n]$ ，要求 $$ \\frac{\\partial}{\\partial p_k} (f + \\lambda(g - 1)) = 0 $$ 将 $f$ 和 $g$ 带入有 $$ \\frac{\\partial}{\\partial p_k} \\left( -\\sum_{k=1}^np_klog_2{p_k} + \\lambda (\\sum_{k=1}^n p_k - 1)\\right) = 0 $$ 计算这 n 个等式的偏微分，我们可以得到： $$ -\\left( \\frac{1}{\\ln(2)} + log_2p_k \\right) + \\lambda = 0 $$ 这说明所有的 $p_i$ 都相等，所以得到 $p_k = \\frac{1}{n}$ 我们可以得到一个结论是：均匀分布的信息熵是最大的 多约束既然可以解决单约束，继续思考一下多约束情况的直观表现，假设我们的约束是两条线，如下图所示 和单约束的解决方法类似，我们画出等高线图，目的就是在约束线上找到一个点可以和等高线相切，所得的值实在约束范围内的最大值或者最小值，直观表示如下图 解算方法是讲单约束的扩展到多约束的情况，较为类似，可举一反三 KKT条件已经解决的在等式约束条件下的求函数极值的问题，那不等式约束条件下，应该如何解决呢？ 这就需要引出KKT条件（Karush-Kuhn-Tucker Conditions），它是在满足一些有规则的条件下，一个非线性规划问题能有最优化解法的一个必要和充分条件 考虑以下非线性最优化问题，含有 $m$ 个不等式约束，$l$ 个等式约束$$\\operatorname*{min}_{x}f(x) \\qquad s.t. \\; g_i(x) \\leqslant 0,\\; h_j(x) =0$$ 必要条件假设 $f,g_i,h_j$ 三个函数为实数集映射，再者，他们都在 $x^$ 这点连续可微，如果 $x^$ 是一个局部极值，那么将会存在一组称为乘子的常数 $\\lambda \\geqslant 0,\\mu_i \\geqslant0, \\nu_j$ 令 $$ \\lambda + \\sum_{i=1}^m \\mu_i + \\sum_{j=1}^l |\\nu_i| \\gt 0, \\\\ \\lambda \\nabla f(x^*) + \\sum_{i=1}^m \\mu_i \\nabla g_i(x^*) + \\sum_{j=1}^l \\nu_i \\nabla h_j(x^*) = 0, \\\\ \\mu_i g_i(x^*) =0 \\; \\text{for all} \\; i=1,\\ldots,m $$ 这里有一些正则性条件或约束规范能保证解法不是退化的（比如$\\lambda$为0），详见 充分条件假设 $f,g_i$ 为凸函数，$h_j$ 函数是仿射函数（平移变换），假设有一个可行点 $x^*$，如果有常数 $\\mu_i \\geqslant 0$ 及 $\\nu_j$ 满足 $$ \\nabla f(x^*) + \\sum_{i=1}^m \\mu_i \\nabla g_i(x^*) + \\sum_{j=1}^l \\nu_i \\nabla h_j(x^*) = 0 \\\\ \\mu_i g_i(x^*) =0 \\; \\text{for all} \\; i=1,\\ldots,m $$ 那么 $x^*$ 就是全局极小值 总结总的来说，拉格朗日乘子法是一个工具（手段或方法），来解决在有约束情况的求函数极值的问题","tags":[{"name":"Theory","slug":"Theory","permalink":"https://charlesliuyx.github.io/tags/Theory/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://charlesliuyx.github.io/tags/Machine-Learning/"}]},{"title":"【直观详解】支持向量机SVM","date":"2017-09-20T01:23:39.000Z","path":"2017/09/19/支持向量机SVM学习笔记/","text":"【阅读时间】13min - 19min【内容简介】详解解读什么是支持向量机，如何解支持向量以及涉及的拉普拉斯乘子法，还有核方法的解读 什么是支持向量机-SVM支持向量机-SVM(Support Vector Machine)从本质来说是一种：用一条线（方程）分类两种事物 SVM的任务是找到这条分界线使得它到两边的margin都最大，注意，这里的横坐标是 $x_1$ 纵坐标为 $x_2$，如下图所示 margin 有了直观的感知，在定义这一节在做一些深入的思考，分解名词（Support Vector Machine）并尝试解释： Machine - Classification Machine 说明它的本质是一个分类器 Support Vector - 如上图所示，在Maximum Margin上的这些点就是支持向量，具体说即最终分类器表达式中只含有这些支持向量的信息，而与其他数据点无关。在下面的公式中，只有支持向量的系数 $\\alpha_i$ 不等于0。说人话，上图中两个红色的点，一个蓝色的点，合起来就是支持向量 $$ \\mathbf w \\cdot \\varphi (\\mathbf x) = \\sum_i \\lambda_i y_i k(\\mathbf x_i,\\mathbf x) $$ 公式中每一个符号的含义在后文有说明 如何求解支持向量机对于我们需要求解的这个超平面（直线）来说，我们知道 它离两边一样远（待分类的两个部分的样本点） 最近的距离就是到支持向量中的点的距离 根据这两点，抽象SVM的直接表达（Directly Representation） 注：$arg \\operatorname*{max}_{x} f(x)$ 表示当 $f(x)$ 取最大值时，x的取值 $$ arg \\operatorname*{max}_{boundary} margin(boundary) \\\\ \\text{所有正确归类的两类到boundary的距离} \\ge margin \\tag{1} $$ 其实这个公式是一点也不抽象，需要更进一步的用符号来表达。 我们知道在准确描述世界运行的规律这件事上，数学比文字要准确并且无歧义的多，文字（例子）直观啰嗦，数学（公式）准确简介 硬间隔 SVM支持向量机 注：公式中加粗或者带有向量箭头的都表达一个向量 假设这些数据线性可分，也可称为硬间隔（Hard Margin） 首先定义超平面：$\\mathbf w^T \\vec x_i + b = 0$，接下来为了方便，设 $\\vec x = (x_1,x_2)$ 即一条直线 任意点 $\\vec x_i$ 到该直线的距离为 $\\frac{1}{\\lVert \\mathbf w \\lVert} (\\mathbf w^T \\vec x_i + b)$ 对于空间内所有训练点的坐标记为 $(\\vec x_i,y_i)$，其中 $y_i$ = 1 or -1， 表示点 $\\vec x_i$ 所属的类 如果这些训练数据是线性可分的，选出两条直线（上图中的虚线），使得他们的距离尽可能的大，这两条直线的中央就是待求的超平面（直线） 为了表达直观，我们定义这两个超平面（直线）分别为 $\\mathbf w^T \\vec x_i + b = 1$ 和 $\\mathbf w^T \\vec x_i + b = -1$，两个超平面（直线）之间的距离为 $\\gamma = \\frac{2}{\\lVert \\mathbf w \\lVert}$ 注：选择1的好处是，w 和b进行尺缩变换（kw和kb）不改变距离，方便计算 为了使得所有样本数据都在间隔区（两条虚线）以外，我们需要保证对于所有的 $i$ 满足下列的条件 $\\mathbf w^T \\vec x_i + b \\geqslant 1$ 若 $y_i = 1$ $\\mathbf w^T \\vec x_i + b \\leqslant -1$ 若 $y_i = -1$ 上述两个条件可以写作 $y_i(\\mathbf w^T \\vec x_i + b) \\geqslant 1, \\;\\text{for all 1}\\; 1\\leqslant i \\leqslant n$ 这里的n指样本点的数量 上面的表达（Directly Representation）可以被写成 $$ arg \\operatorname*{max}_{\\mathbf w,b} \\left\\{ {\\frac{1}{\\lVert \\mathbf w \\lVert} \\operatorname*{min}_{n} [y_i(\\mathbf w^T\\vec x_i}+b)]\\right\\} \\tag{2} $$ 最终目的是找到具有“最大间隔”（Maximum Margin）的划分超平面（直线），找到参数 $\\mathbf w$ 和 $b$ 使得 $\\gamma$ 最大 则可以对(2)式进行形式变换，得到 canonical representation $$ arg \\operatorname*{max}_{\\mathbf w,b} \\frac{2}{\\lVert \\mathbf w \\lVert} \\implies arg \\operatorname*{min}_{\\mathbf w,b} \\frac{1}{2}\\lVert \\mathbf w \\lVert ^2 \\\\ s.t.\\; y_i(\\mathbf w^T\\vec x_i+b) \\geqslant1,\\;i = 1,2,\\ldots,m \\tag{3} $$ 注：s.t. ：subject to 表示约束条件，表达的意思等价于：为了使得所有样本数据都在间隔区（两条虚线）以外 为了解(3)式，需要用到拉格朗日乘子法（Method of lagrange multiplier），它是用来求解在约束条件目标函数的极值的，详细直观详解 注：以下解算过程希望完全看懂强烈建议理解阅读详细直观详解，很多地方推导过程只写必要过程及结论 根据约束的形式，我们引入m个拉格朗日乗法子，记为 $\\boldsymbol \\lambda = (\\lambda_1,\\ldots,\\lambda_m)^T$ ，原因是，有m个约束，所以需要m个拉格朗日乗法子。可以得出拉格朗日方程如下： $$ \\mathcal{L}(\\mathbf w,b,\\boldsymbol \\lambda) = \\frac{1}{2}\\lVert \\mathbf w \\lVert ^2 - \\sum_{i=1}^m \\lambda_i \\{ y_i(\\mathbf w^T\\vec x_i+b) -1 \\} \\tag{4} $$ 解这个拉格朗日方程，对 $\\mathbf w$ 和 $b$ 求偏导数，可以得到以下两个条件 $$ \\mathbf w = \\sum_{i=1}^m \\lambda_i y_i \\vec x_i \\\\ 0 = \\sum_{i=1}^m \\lambda_i y_i $$ 将这两个条件带回公式(4)，可以得到对偶形式（dual representaiton），我们的目的也变为最大化 $\\mathcal{L}(\\boldsymbol \\lambda)$，表达式如下 $$ arg \\operatorname*{max}_{\\boldsymbol \\lambda}\\mathcal{L}(\\boldsymbol \\lambda) = \\sum_{i=1}^m \\lambda_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\lambda_i \\lambda_j \\vec x_i \\vec x_j \\mathbf x_i^T \\mathbf x_j \\\\ s.t. \\qquad \\lambda_i \\geqslant 0, \\forall i\\;;\\quad \\sum_{i=1}^m \\lambda_i y_i = 0 \\tag{5} $$ 以上表达式可以通过二次规划算法解出 $\\boldsymbol \\lambda$ 后，带回，求出$\\mathbf w$ 和 $b$，即可得到模型 $$ f(\\mathbf x) = \\mathbf w^T\\mathbf x + b = \\sum_{i=1}^m \\lambda_i y_i \\mathbf x_i^T \\mathbf x + b \\tag{6} $$ 补充一些关于二次规划算法的相关，(3)式的约束是一个不等式约束，所以我们可以使用KKT条件得到三个条件： $$ \\lambda_i \\geqslant0 ;\\quad y_i f(\\mathbf x_i)-1 \\geqslant0; \\quad \\lambda_i\\{ y_i f(\\mathbf x_i)-1 \\}=0 $$ 使用这些条件，可以构建高效算法来解这个方程，比如SMO（Sequential Minimal Optimization）就是其中一个比较著名的。至于SMO是如何做的，考虑到现代很多SVM的Pakage都是直接拿来用，秉承着前人付出了努力造了轮子就不重复造的核心精神，直接调用就好 软间隔已经说明了如何求得方程，以上的推导形式都是建立在样本数据线性可分的基础上，如果样本数据你中有我我中有你（线性不可分），应该如何处理呢？这里就需要引入软间隔（Soft Margin），意味着，允许支持向量机在一定程度上出错 由上一节我们得知，约束为： $y_i(\\mathbf w^T\\vec x_i+b) \\geqslant1,\\;i = 1,2,\\ldots,m$ ，目标是使目标函数可以在一定程度不满足这个约束条件，我们引入常数 $C$ 和 损失函数 $\\ell_{0/1}(z)$ 为0/1损失函数，当z小于0函数值为1，否则函数值为0 $$ \\operatorname*{min}_{\\mathbf w,b} \\frac{1}{2}\\lVert w \\lVert^2 + C \\sum_{i=1}^m \\ell_{0/1}(y_i(\\mathbf w^T\\vec x_i+b) -1) \\tag {7} $$ 对于(7)式来说 $C \\geqslant 0$ 是个常数，当C无穷大时，迫使所有样本均满足约束；当C取有限值时，允许一些样本不满足约束 但 $\\ell_{0/1}(z)$ 损失函数非凸、非连续，数学性质不好，不易直接求解，我们用其他一些函数来代替它，叫做替代损失函数（surrogate loss） $$ \\begin{align} & \\text{hinge损失:} \\ell_{hinge}(z) = max(0,1-z)\\\\ & \\text{指数损失:} \\ell_{exp}(z) = e^{-z}\\\\ & \\text{对数损失:} \\ell_{log}(z) = log(1+e^{-z})\\\\ \\end{align} $$ 三种常见损失函数如下图 为了书写方便，我们引入松弛变量（slack variables）: $\\xi_i \\geqslant 0$，可将(7)式重写为 $$ \\operatorname*{min}_{\\mathbf w,b,\\xi_i} \\frac{1}{2}\\lVert w \\lVert^2 + C \\sum_{i=1}^m \\xi_i \\\\ s.t. \\quad y_i(\\mathbf w^T\\vec x_i+b) \\geqslant 1 - \\xi_i ;\\; \\xi_i \\geqslant 0,\\; i = 1,2,\\ldots,m \\tag{8} $$ (8)式就是常见的软间隔支持向量机，其中，每一个样本都有一个对应的松弛变量，用以表征该样本不满足约束的程度，求解的方法同理硬间隔支持向量机 支持向量机扩展核方法以上我们求解的支持向量机都是在线性情况下的，那么非线性情况下如何处理？这里就引入：核方法 对于这样的问题，可以将样本从原始空间映射到一个更高为的特征空间，使得样本在这个特征空间内线性可分，直观可视化解释 为了完成这个目的，令 $\\phi(\\mathbf x)$ 表示将 $\\mathbf x$ 映射后的特征向量，于是，在特征空间划分超平面所对应的模型可表示为： $$ f(\\mathbf x) = \\mathbf w^T \\phi(\\mathbf x) + b $$ 同理上文中引入拉格朗日乘子，求解整个方程后可得 $$ \\begin{align} f(\\mathbf x) &= \\mathbf w^T \\phi(\\mathbf x) + b \\\\ &= \\sum_{i=1}^m \\lambda_i y_i \\phi(\\mathbf x_i)^T \\phi(\\mathbf x) + b \\\\ &= \\sum_{i=1}^m \\lambda_i y_i k(\\mathbf x,\\mathbf x_i)+ b \\end{align} $$ 这里的函数 $k(\\cdot,\\cdot)$ 就是核函数（kernel function），常见的核函数见下表 名称 表达式 参数 线性核 $\\boldsymbol x_i^T \\boldsymbol x_j$ 无 多项式核 $(\\boldsymbol x_i^T \\boldsymbol x_j)^d$ $d \\geqslant 1$ 多项式次数 高斯核 $exp(-\\frac{\\lVert\\boldsymbol x_i - \\boldsymbol x_j \\lVert^2}{2\\sigma^2})$ $\\sigma&gt;0$ 高斯核带宽 拉普拉斯核 $exp(-\\frac{\\lVert\\boldsymbol x_i - \\boldsymbol x_j \\lVert^2}{\\sigma})$ $\\sigma&gt;0$ Sigmoid核 $tanh(\\beta \\boldsymbol x_i^T\\boldsymbol x_j + \\theta)$ $\\beta&gt;0$ $\\theta&gt;0$ 也可以通过函数组合得到这些值 多类问题多类问题可以使用两两做支持向量机，再由所有的支持向量机投票选出这个类别的归属，被称为one-versus-one approace。 Reference知乎各类回答Wiki百科PRML周志华-机器学习","tags":[{"name":"Theory","slug":"Theory","permalink":"https://charlesliuyx.github.io/tags/Theory/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://charlesliuyx.github.io/tags/Machine-Learning/"}]},{"title":"Dota2伤害类型详解","date":"2017-09-18T21:31:12.000Z","path":"2017/09/18/Dota2伤害类型详解/","text":"【阅读时间】5min 百科类【内容简介】有关Dota2所有伤害来源的总结和互相作用总结，方便查阅 伤害来源攻击伤害主要来自于普通物理攻击 - 平A 具体计算方式 技能伤害详情参见 包含了所有来自技能的伤害，三种类型：魔法，物理和纯粹 伤害类型互相作用机制表格 游戏机制 物理攻击 物理技能 魔法伤害 纯粹伤害 护甲 降低 降低 正常 正常 伤害格挡 降低 正常^1 正常 正常 魔法抗性 正常 正常 降低 正常 虚无 没有效果 美国效果 降低 正常 闪避 可能落空 正常 正常 降低 致盲 可能落空 正常 正常 正常 伤害加深^2 加深 加深 加深 加深 伤害减免^2 降低 降低 降低 降低 伤害无效化^2 没有效果 没有效果 没有效果 没有效果 魔法伤害护盾 正常 正常 没有效果 正常 无敌 没有效果 没有效果 没有效果 没有效果 技能免疫 正常 不定 不定 不定 物理与护甲和伤害格挡有关，虚无和一些技能可以造成物理免疫，召唤单位和守卫的平A也是物理攻击 物理免疫技能炼金术士：酸性喷雾 炼金术士：不稳定化合物 敌法师：法力损毁 兽王：野性飞斧 赏金猎人：暗影步 钢背兽：针刺扫射 人马：反击 克林克次：灼热之箭 戴泽：剧毒之触 戴泽：暗影波 死亡先知：驱使恶灵 龙骑士：古龙形态溅射 上古巨神：裂地沟壑 上古巨神：回音重踏 灰烬之灵：无影拳 主宰：无敌斩 昆卡：潮汐使者 拉席克：恶魔赦令 噬魂鬼：盛宴 露娜：月刃 马格纳斯：加强力量溅射 司夜刺客：复仇 剃刀：风暴之眼 力丸：背刺 斯拉达：鱼人碎击 斯拉达：重击 狙击手：爆头 熊灵：缠绕之爪 斯温：巨力挥舞 圣堂刺客：隐匿 潮汐猎人：锚机 熊战士：怒意狂击 冥界亚龙：幽冥剧毒 编织者：虫群 魔法大多数技能都是魔法伤害，虚无状态会承受更多伤害 在纯粹和物理技能中未提及的都是魔法伤害 纯粹纯粹伤害能作用与技能免疫单位，不能作用于无敌单位 斧王-反击螺旋 祸乱之源：蚀脑 祸乱之源：噩梦 嗜血狂魔：血之祭祀 嗜血狂魔：割裂 陈：忠诚考验 末日使者：末日 魅惑魔女：推进 谜团：午夜凋零 谜团：黑洞 祈求者：炎阳冲击 杰奇洛：A烈焰焚身 莉娜：A神灭斩 美杜莎：（石化）秘术异蛇 司夜刺客：尖刺外壳 全能骑士：洗礼 殁境神蚀者：奥术天球 帕吉：肉钩 痛苦女王：超声冲击波 沉默术士：智慧之刃 幽鬼：荒芜 圣堂刺客：灵能之刃 伐木机：锯齿飞轮 伐木机：伐木锯链 伐木机：死亡旋风 修补匠：激光 骨灰 标记是一种特殊标记，为的是与其他技能区分开来 生命移除标记某些生命移除标记的技能可以立即杀死幻想 干扰者：恶念瞥视 莱恩：妖术 莱恩：法力抽取 美杜莎：石化凝视 帕格纳：生命吸取 羊刀：变羊 暗影萨满：变羊 有些技能利用生命移除来制造生命消耗效果，通常都是非致命伤害，伤害类型也是纯粹，被标记为生命移除 臂章：扣血 哈斯卡：沸血之矛对自身 艾欧：过载 凤凰：凤凰冲击 凤凰：烈火精灵 凤凰：烈日炙烤 魂戒：献身 工程师：自爆起飞 不朽尸王：噬魂 不反弹标记不反弹标记会使得一些受到伤害事件不会与带有不反弹标记的伤害相互作用，这防止了无限伤害循环( 刃甲：反弹伤害 司夜刺客：尖刺外壳 冥界亚龙：腐蚀皮肤 术士：致命链接","tags":[{"name":"Dota2","slug":"Dota2","permalink":"https://charlesliuyx.github.io/tags/Dota2/"},{"name":"Mechanism","slug":"Mechanism","permalink":"https://charlesliuyx.github.io/tags/Mechanism/"}]},{"title":"【直观详解】机器学习分类器性能指标详解","date":"2017-09-12T20:05:32.000Z","path":"2017/09/12/机器学习分类器性能指标详解/","text":"【阅读时间】16 - 26 min【内容简介】系统详解分类器性能指标，什么是准确率 - Accuracy、精确率 - Precision、召回率 - Recall、F1值、ROC曲线、AUC曲线、误差 - Error、偏差 - Bias、方差 - Variance及Bias-Variance Tradeoff 在任何领域，评估（Evaluation）都是一项很重要的工作。在Machine Learning领域，定义了许多概念并有很多手段进行评估工作 混淆矩阵 - Confusion Matrix准确率定义：对于给定的测试数据集，分类器正确分类的样本数与总样本数的之比 通过准确率，的确可以在一些场合，从某种意义上得到一个分类器是否有效，但它并不总是能有效的评价一个分类器的工作。一个例子，Google抓取了100个特殊页面，它的索引中有10000000页面。随机抽取一个页面，这是不是特殊页面呢？如果我们的分类器确定一个分类规则：“只要来一个页面就判断为【不是特殊页面】”，这么做的效率非常高，如果计算按照准确率的定义来计算的话，是(9,999,900/10,000,000) = 99.999%。虽然高，但是这不是我们并不是我们真正需要的值，就需要新的定义标准了 对于一个二分类问题来说，将实例分为正类（Positive/+）或负类（Negative/-），但在使用分类器进行分类时会有四种情况 一个实例是正类，并被预测为正类，记为真正类（True Positive TP/T+） 一个实例是正类，但被预测为负类，记为假负类（False Negative FN/F-） 一个实例是负类，但被预测为正类，记为假正类（False Positive FP/F+） 一个实例是负类，但被预测为负类，记为真负类（True Negative TN/F-） TP和TN中的真表示分类正确，同理FN和FP表示分类错误的 为了全面的表达所有二分问题中的指标参数，下列矩阵叫做混淆矩阵 - Confusion Matrix，目的就是看懂它，搞清楚它，所有模型评价参数就很清晰了 DiagnosticTesting Diagram Relationships between various measures of diagnostic testing by CMG Lee. In the SVG image, hover over a block or relation to highlight it. #mainsvg { font-family:Helvetica,Arial,sans-serif; font-size:6px; text-anchor:middle; stroke-linejoin:round; stroke-linecap:round; stroke-width:0.7; fill:none; stroke-opacity:1; fill-opacity:1; } #mainsvg:hover { stroke-opacity:0.25; fill-opacity:0.25; } .active:hover { stroke-opacity:1; fill-opacity:1; } text { fill:#000000; cursor:default; } .label { stroke:none; fill:#000000 } .op { stroke-width:0.15; font-size:5px; font-weight:bold; } + &#247; &#247; &#247; + &#247; &#247; +,&#247; &#247; F1 s.F1 score = 2 / (1 / Recall + 1 / Precision) ACCAccuracy = (&#931; True positive + &#931; True negative) / &#931; Total population DORDiagnostic odds ratio = Positive likelihood ratio / Negative likelihood ratio LR+Positive likelihood ratio = True positive rate / False positive rate LR&#8722;Negative likelihood ratio = False negative rate / True negative rate FDRFalse discovery rate = &#931; False positive / &#931; Predicted condition positive PPVPositive predictive value, Precision = &#931; True positive / &#931; Predicted condition positive NPVNegative predictive value = &#931; True negative / &#931; Predicted condition negative FORFalse omission rate = &#931; False negative / &#931; Predicted condition negative TPRTrue positive rate, Recall, Sensitivity, probability of detection = &#931; True positive / &#931; Condition positive FNRFalse negative rate, Miss rate = &#931; False negative / &#931; Condition positive FPRFalse positive rate, Fall-out, probability of false alarm = &#931; False positive / &#931; Condition negative TNRTrue negative rate, Specificity = &#931; True negative / &#931; Condition negative prev.Prevalence = &#931; Condition positive / &#931; Total population pop.Total population = Condition positive + Condition negative = Predicted condition positive + Predicted condition negative 样本空间 = 正类 + 负类 = 预测结果正类 + 预测结果负类 Pc&#8722;Predicted condition negative = False negative + True negative Pc+Predicted condition positive = True positive + False positive C+Condition positive = True positive + False negative C&#8722;Condition negative = False positive + True negative T&#8722;负类中预测正确的部分 F&#8722;负类中预测错误的部分 F+正类中预测错误的部分 T+正类中预测正确的部分 通过上面的的讨论已经有T+:TP F+:FP T-:TN F-:FN C+:样本正类 C-:样本负类 Pc+:预测正类 Pc-:预测负类 用样本中的正类和负类进行计算的定义 缩写 全称 等价称呼 计算公式 TPR True Positive Rate 真正类率 Recall Sensitivity $ \\frac {\\sum T+}{\\sum C+}$ FNR False Negative Rate 假负类率Miss rate Type rs error $ \\frac {\\sum F-}{\\sum C+}$ FPR False Positive Rate 假正类率fall-out Type 1 error $ \\frac {\\sum F+}{\\sum C-}$ TNR Tre Negative Rate 真负类率Specificity $ \\frac {\\sum T-}{\\sum C-}$ 用预测结果的正类和负类进行计算的定义 缩写 全称 等价称呼 计算公式 PPV Positive Predictive Value 正类预测率Precision $ \\frac {\\sum T+}{\\sum Pc+}$ FOR False Omission Rata 假错误率 $ \\frac {\\sum F-}{\\sum Pc-}$ FDR False Discovery Rate 假发现率 $ \\frac {\\sum F+}{\\sum Pc+}$ NPV Negative Predictive Value 负类预测率 $ \\frac {\\sum T-}{\\sum Pc-}$ 其他定义概念 缩写 全称 等价称呼 计算公式 ACC Accuracy 准确率 $ \\frac {\\sum (T+) + \\sum {T-}}{样本空间}$ LR+ Positive Likelihood Ratio 正类似然比 $ \\frac {TPR}{FPR}$ LR- Negative likelihood ratio 负类似然比 $ \\frac {FNR}{TNR}$ DOR Diagnostic odds ratio 诊断胜算比 $ \\frac {LR+}{LR-}$ F1 score $F_1$ test measure F1值 $\\frac{2}{\\frac{1}{recall}+\\frac{1}{precision}}$ MCC Matthews Correlation coefficient 马修斯相关性系数 $\\frac{TP \\times TN - FP \\times FN}{\\sqrt {(TP + FP)(TP + FN)(TN + FP)(TN +FN)}}$ LR+/-指的是似然比，LR+ 越大表示模型对正类的分类越好，LR-越大表示模型对负类的分类效果越好 F1值是精确值和召回率的调和均值，其实原公式是 $F_\\beta = (1 + \\beta^2)\\frac{precision \\times recall}{(\\beta^2recall)+recall}$，这里的β表示：召回率的权重是准确率的β倍。即F值是一种精确率和召回率的综合指标，权重由β决定 MCC值在[-1,1]之间，靠近1表示完全预测正确，靠近-1表示完全悖论，0表示随机预测 最终为了不那么麻烦，说人话，还是一图胜千言 Precision - Recall 图片详解： 左边暗一些部分的点都是真正的正类，右边亮一些部分的点都是真正的负类 中间的一个圆圈就是我们的正类分类器：注意，这个圈是的预测结果都是正类，也就是说在这个分类器看来，它选择的这些元素都是它所认为的正类，对应的，当然是圈以外的部分，也就是预测结果是负类的部分 底下的Precision和Recall示意图也相当的直观，看一下就能明白 ROC CurveROC - Receiver Operating Characteristic Curve，接受者操作特征曲线，ROC曲线 这个曲线乍看下为啥名称那么奇怪呢，原来这个曲线最早是由二战中的电子工程师和雷达工程师发明的，用来侦测战场上的敌军飞机，舰艇等，是一种信号检测理论，还被应用到心理学领域做知觉检测。 什么是ROC曲线ROC曲线和混淆矩阵息息相关，上一部分已经详细解释了相关内容，这里直接说明ROC曲线的横坐标和纵坐标分别是什么 横坐标：FPR假正类率，纵坐标：TPR真正类率 初看之下你不懂一个曲线表示的什么意思，那么看几个特征点或特殊曲线是一个非常好的方法。按照这种方法来分析ROC曲线： 第一个点：(0,1)，FPR=0 TPR=1 ，这意味着所有的正类全部分类正确，或者说这是一个完美的分类器，将所有的样本都分类正确了 第二个点：(1,0)， FPR=1 TPR=0 ，和第一个点比较，这是第一个点的完全反面，意味着是个最糟糕的分类器，将所有的样本都分类错误了（但其实可以直接取反，就是最好的模型，因为是二分类问题） 第三个点：(0,0)，FPR=0 TPR=0 也就是原点，这个点表示的意思是，分类器预测所有的样本都为负类 第四个点：(1,1)，FPR=1 TPR=1，和第三个点对应，表示分类器预测所有的样本都为正类 一条线：y=x。这条对角线上的点实际上就是一个采用随机猜测策略的分类器的结果 总结来说，ROC曲线的面积越大，模型的效果越好；ROC曲线光滑以为着Overfitting越少 还是一图胜千言 ROC曲线解释 $TPR = \\frac{TP}{TP+FN}$ $FPR = \\frac{FP}{FP+TN}$ 蓝色图像是正类分类器的概率分布，红色图像负类分类器的概率分布，竖直的黑线是阈值（Threshold），二分类分类器的输出就是一个取值在[0,1]间的值（概率），我们将黑线从0移动到1，就能得出一条曲线，这条线就是ROC曲线 如果问这个分类器画成的图像为何是一个类似帽子的形状，例子是最佳的说明方法，我们就来算一个ROC曲线看看，下图是20个测试样本的结果，“Class”一栏表示每个测试样本真正的标签（p表示正类，n表示负类），“Score”表示每个测试样本属于正样本的概率，Inst#是序号数 example-data 接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值（和你的测试样本的数量有关），将它们画在ROC曲线的结果如下图： example-roc-curve 当然我们也可以曲很多个阈值画曲线，不一定非要从测试样本的结果中取20个 为什么使用ROC曲线ROC曲线有一个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和Precision-Recall曲线的对比： ROC-PrecisionRecall 在上图中，(a)和(c)为ROC曲线，(b)和(d)为Precision-Recall曲线。 (a)和(b)展示的是分类其在原始测试集（正负样本分布平衡）的结果，(c)和(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果。可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线则变化较大，记住这个结论即可 PRC Curve在上面提到了一个指标，PRC - Precision-Recall 曲线，画法和ROC很相似，但是使用值是Precision和Recall AUC ValueAUC - Area Under Curve被定义为ROC曲线下的面积 AUC在[0.5,1]之间，这是因为ROC曲线一般都处于y=x这条直线的上方（否则这个做分类器的人连简单的取非都不会真可以去死了） AUC值越大，证明这个模型越好 Bias-Variance Tradeoff三个名词，Error误差 Bisa偏差 Variance方差 三个名词表示了什么再来一次，一图胜千言 准：Bias 描述的是根据样本训练的模型的输出预测结果的期望与样本真实结果的差距，说人话，这个模型对样本拟合的好不好。想在Bias上表现好，降低Bias，就是复杂化模型，增加模型的参数，但这样容易过拟合（Overfitting）Low Bias对应的就是点都在靶心附近，所以瞄的都是准的，但手不一定稳 确：Variance 描述的是根据样本训练的模型在测试集上的表现（泛化能力） ，想在Variance上表现好，降低Variance，需要简化模型，减少模型的参数，这样做容易欠拟合，对应上图的High Bias，点偏离的中心。Low Variance对应的是点打的都很集中，但不一定在靶心附近，手很稳，但是瞄的不准 要准确表达这两个定义的含义必须要使用公式化的语言，不得不感叹，在准确描述世界运行的规律这件事上，数学比文字要准确并且无歧义的多，文字（例子）直观啰嗦，数学（公式）准确简介 我们假设有这样的一个函数，$y=f(x) + \\epsilon$ ，其中噪声 $\\epsilon$ 均值为0，方差为 $\\sigma^2$ 我们的目的是去找到一个函数 $\\hat {f}(x)$ 尽可能接近 $f(x)$ ，我们可以用均方误差（MSE）或者交叉熵，或者DL散度来表示这个接近程度，我们希望 $(y - \\hat f(x) )^2$ 对样本空间内的所有样本和测试集中的所有样本都最小 机器学习核心就是用各种不同的算法去找这个 $\\hat f$，希望最小，那就使用一个公式来表征这个值得大小，即期望，也称Total Error（误差），在机器学习的训练中，这个值是评判模型好坏最重要：$$E[(y - \\hat f(x))^2] = Bias[\\hat f(x)]^2 + Var[\\hat f(x)] + \\sigma^2$$ 其中 $Bias[\\hat f(x)] = E[\\hat f(x) - f(x)]$，且 $Var[\\hat f(x)] = E[\\hat f(x)^2] - E[\\hat f(x)]^2$ Bias-Variance Tradeoff作为机器学习一个核心训练的观点或者说概念，推导觉得还是十分重要，整理如下 推导过程为了公式简介，把 $f(x)$ 与 $\\hat f(x)$ 简写为 $f$ 与 $\\hat f$ ，记随机变量为 $X$，有$$Var[X] = E[X^2] - E[X]^2 \\implies E[X^2] = Var[X] + E[X]^2$$ 因为 $f$ 是一个已经确定的函数，所以 $E[f] = f$ 成立 根据 $y = f + \\epsilon$ 和 $E[\\epsilon] = 0$ 有$$E[y] = E[f + \\epsilon] = E[f] = f$$噪声的方差 $ Var[\\epsilon] = \\sigma^2$ $$ Var[y] = E[(y-E[y])^2] = E[(y - f)^2] = E[(f + \\epsilon - f)^2] = E[\\epsilon^2] = Var[\\epsilon] + E[\\epsilon]^2 = \\sigma^2 $$ 由于 $\\epsilon$ 和 $\\hat f$ 互相独立 $$ \\begin{align} E[(y - \\hat f)^2] & = E[y^2 + \\hat f^2 - 2y\\hat f] \\\\ & = E[y^2] + E[\\hat f^2] - E[2y\\hat f] \\\\ & = Var[y] + E[y]^2 + Var[\\hat f] + E[\\hat f]^2 - 2fE[\\hat f] \\\\ & = Var[y] + Var[\\hat f] + (f^2 - 2fE[\\hat f] + E[\\hat f]^2) \\\\ & = Var[y] + Var[\\hat f] + (f - E[\\hat f])^2 \\\\ & = \\sigma^2 + Var[\\hat f] + Bias[\\hat f]^2 \\end{align} $$ 总结感觉在实际使用中，你不需要去自己写代码来画这些曲线，只要是框架是一定整合了这些值得结果，但是知其然知其所以然，越了解它是如何画的，越能处理奇怪的特殊情况 常见的处理方式是记下来所有指标的结果，即这些指标怎么变，表示了模型的那些方面好或者坏的结论，但是如果在特殊的问题出现了不在你看的结果中的情况可能还是会捉襟见肘，还是脚踏实地，能看见更大的世界！","tags":[{"name":"Theory","slug":"Theory","permalink":"https://charlesliuyx.github.io/tags/Theory/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://charlesliuyx.github.io/tags/Machine-Learning/"}]},{"title":"【直观详解】信息熵、交叉熵和相对熵","date":"2017-09-11T07:25:49.000Z","path":"2017/09/11/什么是信息熵、交叉熵和相对熵/","text":"【阅读时间】10min - 13min【内容简介】使用一个现实中直观的例子详解信息熵、交叉熵及相对熵的核心概念，读完后，希望能帮助你建立起这三个概念的固有直觉，不再疑惑 要完成题目的最终解释，必须从熵这个神奇的概念开始讲起 什么是熵 - Entropy词源 - 最初来源于热力学Entropy来源于希腊语，原意：内向，即：一个系统不受外部干扰时往内部稳定状态发展的特性。定义的其实是一个热力学的系统变化的趋势 $$\\Delta S = \\frac{Q}{T} = \\frac{热量}{温度} \\tag{1-1}$$1923年，德国科学家普朗克来中国讲学用到entropy这个词，胡刚复教授看到这个公式，创造了“熵”字，因为“火”和热量有关，定义式又是热量比温度，相当自洽 信息论信息论中，熵是接受的每条消息中包含的信息的平均值。又被称为信息熵、信源熵、平均自信息量。可以被理解为不确定性的度量，熵越大，信源的分布越随机 1948年，由克劳德·爱尔伍德·香农将热力学中的熵引入信息论，所以也叫做：香农熵 生态学在生态学中，熵表示生物多样性的指标 广义的定义熵是描述一个系统的无序程度的变量；同样的表述还有，熵是系统混乱度的度量，一切自发的不可逆过程都是从有序到无序的变化过程，向熵增的方向进行 我们接下来要讨论的信息熵 交叉熵 相对熵 更多的着眼于信息论的角度，换句话说，更加关注概率和不确定性 什么是信息熵、交叉熵、相对熵可以将对熵的理解从简单到复杂依次分解成三个层次来理解 如何衡量不确定事物的发生？数学是一种工具，使用数学来描述现实中的各种事物是一个数学家本质的工作目标。而现实中不确定性，或者说不太确定是否会发生的事件必须要找到一种抽象的、符号化和公式化的手段去表示。 比如天气情况，假设可能有【阴、晴、雨、雪】四种情况，使用概率符号表示 $\\mathbf P = [p_1,p_2,p_3,p_4]$，接下来自然而然的思考：那么，什么条件（情况）会影响这些值呢？ 假设有一下三种描述，或者说条件 今天是晴天，所以明天可能也是晴天 天气预报说明天下雨 9月12日苹果公司举行发布会 那么这三个描述中，很明显，第二条的信息量更大，因为它可以使得不确定事件发生在 $p_3$ 的概率更大。类似的，第三条对判断毫无帮助，信息量为0。注意，信息量不等于信息熵，如果是这样，那么直接用概率来衡量就可以了，不需要在重新定义一个概念 其实信息熵是信息量的期望（均值），它不是针对每条信息，而是针对整个不确定性结果集而言，信息熵越大，事件不确定性就越大。单条信息只能从某种程度上影响结果集概率的分布 考虑到信息冗余，信息量存储下来究竟需要多大空间？我们已经有了 $\\mathbf P = [p_1,p_2,p_3,p_4]$ 来表示天气情况，那么用计算机来存储每天的天气，那该如何编码呢？ 常见的做法是，4个不同的信息，只需要2bit就能做到，00 01 11 10，假设我们在南方城市，肯定要把00编码成雨天，这样可以节省存储空间，至于为什么能节省存储空间，这就要讨论编码方式。可以简单的理解为，如果一串信息一串0很多，可以通过编码压缩这一群0来节省空间 使用一个公式来计算记录n天数据需要的存储空间：Sn $$ S_n = n \\times \\sum_{i = 1}^4{\\left(P_i \\times F(P_i) \\right) } \\tag{2-1} $$ $P_i$ 表示第i个事件发生的概率；$F(P_i)$ 表示存储空间的存储因子 如何确定这个函数 $F(P_i)$ 的形式？考虑这个函数需要满足条件：概率大的事件对应小的存储空间，说人话，就是成反比，你的数学功底不错的话，脑海中第一反应出来满足这个条件最直观是反比例函数，说人话， $\\frac{1}{P_i}$ 。 之后我们发现这个公式中有个除法非常讨厌，我们想着去掉它，脑海中第一反应出来的满足这个条件的一定是取对数，至于为什么取对数，那说道就很多，取对数是指数的逆操作， 对数操作可以让原本不符合正态分布的模型符合正态分布，比如随着模型自变量的增加，因变量的方差也增大的模型取对数后会更加稳定 取对数操作可以rescale（原谅我，这里思前想后还是感觉一个英文单词更加生动）其实本质来说都是因为第一点。说人话版本，人不喜欢乘法，对数可以把乘法变加法 那么我们结束清楚之后，就很容易就可以定义出$$F(P_i) = \\log_a ({\\frac{1}{P_i}}) \\tag{2-2}$$ a作为底数，可以取2（处理2bit数据），10（万金油），e（处理正态分布相关的数据） 结合对信息熵的定义（第一节最后的粗体字）然后把（2-2）带入（2-1），就会发现，哦！看着有点眼熟啊$$H(P) = \\sum_i {P(i)log_a {\\frac{1}{P(i)}}} = - \\sum_i {P(i)log_a {P(i)}} \\tag{2-3}$$这这这，就是信息熵的定义式吧？总结就发现，信息熵其实从某种意义上反映了信息量存储下来需要多少存储空间 总结为：根据真实分布，我们能够找到一个最优策略，以最小的代价消除系统的不确定性（比如编码），而这个代价的大小就是信息熵 理解基于信息熵的交叉熵和相对熵因为是我们用2bit模式存储，为了计算方便，这里取a = 2 先计算刚刚有关天气问题 $\\mathbf P = [p_1,p_2,p_3,p_4]$ ：【阴、晴、雨、雪】的信息熵，假设我们对天气的概率一无所知，那么四种天气的发生概率为等概率（服从平均分布），即 $\\mathbf P = [\\frac {1}{4},\\frac {1}{4},\\frac {1}{4},\\frac {1}{4}]$ ，带入公式2-3，得到 $H(P) = 2$ ，存储信息需要的空间 $S_n = 2n$ 继续思考，假设我们考虑天气的城市是一个地处中国南方雨季的城市，那么阴天和雨天的概率从经验角度（先验概率）来看大于晴天雪天，把这种分布记为 $\\mathbf Q = [\\frac{1}{4},\\frac{1}{8},\\frac{1}{2},\\frac{1}{8}]$，带入公式2-3，信息熵 $H(Q) = 1.75$，存储信息需要的空间 $S_n = 1.75n$ 直观的来考虑上面不同的两种情况，明显当事件的不确定性变小时候，我们可以改变存储策略（00 雨天 01 阴天），再通过编码，节省存储空间。信息熵的大小就是用来度量这个不确定大小的 关于编码的方式，这里提一下，哈夫曼树与哈夫曼编码 ，有兴趣的读者可以去研究一下 交叉熵的由来我们把这个问题再扩展一下 天气【阴、晴、雨、雪】 信息熵 $\\mathbf P = [\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4}]$ $H(P) = 2$ $\\mathbf Q = [\\frac{1}{4},\\frac{1}{8},\\frac{1}{2},\\frac{1}{8}]$ $H(Q) = 1.75$ $\\mathbf Z = [\\frac{1}{8},\\frac{1}{16},\\frac{3}{4},\\frac{1}{16}]$ $H(Z) = \\frac{7}{8}+\\log_2 {\\frac{4}{3}} = 1.29$ $\\mathbf W = [0,0,1,0]$ $H(W) = 0$ 接下来，假定在确定性更大的概率分布情况下，用更不确定的存储策略来计算，比如使用 $\\mathbf P$ 的概率乘上 $\\mathbf Q$ 的存储因子，套用公式2-3$$H(\\mathbf Q,\\mathbf P) = \\sum_i {P(i) \\log_a {\\frac{1}{Q(i)}}} \\tag{3-1}$$顾名思义，看公式3-1的形式，就不难发现，这就是所谓的交叉熵，计算可得 交叉熵 P Q Z W P $H(P,P) = 2$ $H(P,Q) = 2.25$ $H(P,Z) = \\frac{11}{4}+\\frac{1}{4}\\log_2 {\\frac{4}{3}} = 2.85$ +inf Q $H(Q,P) = 2$ $H(Q,Q) = 1.75$ $H(Q,Z) = \\frac{7}{4}+\\frac{1}{2}\\log_2 {\\frac{4}{3}} = 1.96$ +inf Z $H(Z,P) = 2$ $H(Z,Q) = 1.375$ $H(Z,Z) = \\frac{7}{8}+\\log_2 {\\frac{4}{3}} = 1.29$ +inf W $H(W,P) = 2$ $H(W,Q) = 1$ $H(W,Z) = \\log_2 {\\frac{4}{3}} = 0.415$ $H(W,W) = 0$ 上表直观的展现的交叉熵的数值表现，PQZW依次不确定性越来越低，极端情况的W不确定性为0，即是确定的 交叉熵，用来高衡量在给定的真实分布下，使用非真实分布指定的策略消除系统的不确定性所需要付出努力的大小 总的来说，我们的目的是：让熵尽可能小，即存储空间小（消除系统的不确定的努力小）。（不要问为什么想要存储空间小，这都是钱更是效率和时间） 通过上表我们发现一个规律，为了让熵小，解决方案是：是用确定性更大的额概率乘以确定性更小的存储因子，比如不确定性越大的概率分布，如P概率分布，其信息熵越大；基于同一真实（确定性）分布的情况下，套用不确定性更大的存储因子，如P的存储因子，得出的交叉熵越大 在机器学习中，即用测试结果集（样本结果集）的概率乘以训练出来的结果集存储因子，而在不断的训练过程中，我们要做的就是通过不断调整参数，降低这个值，使得模型更加的稳定，不确定性越来越小，即突出需要表征的数值的特点（白话文也就是分类的效果更好） 相对熵的由来有了信息熵和交叉熵后，相对熵是用来衡量两个概率分布之间的差异，记为 $D(P||Q) = H(P,Q) - H(P)$，也称之为KL散度$$D_{KL}(P||Q) = \\sum_i{P(i) \\log_a {\\frac{P(i)}{Q(i)}}}$$当 $P(i) = Q(i)$ 的时候，该值为0，深度学习过程也是一个降低该值的过程，该值越低，训练出来的概率Q越接近样本集概率P，即越准确，或者可以理解为相对熵一把标尺，用来衡量两个函数是否相似，一样就是0，当然，这种解释十分牵强，但是更直观 关于底数 $a$ 的选择问题，其实和概率分布的情况是分不开的。比如使用2进制编码，那么所能表示的不同情况的数量，$\\sum_{i=0}^N 2^i$，我们知道，指数函数变化率变化很大，不好分析，稳定性差。对数操作可以乘法变加法，指数放下来，是十分好用的数学工具（其实是一种变换域的思想，这种思想在整个信息论，统计学中处处可见） 比如使用 $ln()$ 的时候，对应的分布，其实是正态分布，很好理解，正太分布的底数是 $e$","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://charlesliuyx.github.io/tags/Machine-Learning/"},{"name":"Infomation Theory","slug":"Infomation-Theory","permalink":"https://charlesliuyx.github.io/tags/Infomation-Theory/"}]},{"title":"Dota2机制总结","date":"2017-09-06T06:50:56.000Z","path":"2017/09/05/Dota2机制总结/","text":"【阅读时间】百科类型文章【内容简介】这是一份有关Dota2游戏机制的总结，核心目的是为了方便查阅，计算公式。针对人群是对数据和游戏机制有很大兴趣的高玩，从中你可能能了解如何通过击杀或得更多的经济，哪些操作可以躲避技能等等 版本信息：更新到7.06f 金钱击杀英雄奖励获得金钱 = 110 + 连杀奖励 + （被击杀者等级 * 8） 连杀奖励 = 60 * （连杀数-2）[大于0] 助攻奖励 助攻英雄数 获得金钱 1 [140 + (5 × 被击杀者等级) + (0.0375 × 被击杀者净收入 × 净收入因子) + (100 × 团队净收入之差 / 4000)] 2 [70 + (4 × 被击杀者等级) + (0.0375 × 被击杀者净收入 × 净收入因子) + (75 × 团队净收入之差 / 4000)] 3 [35 + (3 × 被击杀者等级) + (0.0375 × 被击杀者净收入 × 净收入因子) + (50 × 团队净收入之差 / 4000)] 4 [25 + (2 × 被击杀者等级) + (0.03 × 被击杀者净收入 × 净收入因子) + (35 × 团队净收入之差 / 4000)] 5 [20 + (1 × 被击杀者等级) + (0.0225 × 被击杀者净收入 × 净收入因子) + (25 × 团队净收入之差 / 4000)] 净收入因子 = (敌方队伍净收入 / 友方队伍净收入) - 1，最小值为0，最大值为1 还需要 × [1.2 - 0.1 × (被击杀者净收入排名 -1)] × [净收入排名因子] Roshan200 团队奖励 150 - 400 击杀奖励 死亡掉钱损失不可靠金钱 = 50 + 财产总和 ÷ 40 5千经济 ➜ 175；1万经济 ➜ 290；2万经济 ➜ 550 复活复活时间 每级增加2秒 每到6级的倍数增加10秒 18级后每级增加4秒 买活花费买活金钱 = 100 + (英雄等级 英雄等级 1.5) + (游戏时间(s) * 0.25 ) 放弃比赛掉线超过5分钟后，所有金钱被队友平分 物理攻击伤害最终攻击伤害 $$ 最终攻击伤害 = \\\\ \\{ [\\text {MD} × (1 + \\sum \\text {PBD}) + \\text {FBD}] \\times \\text {CSM} - \\text {BD} \\}\\\\ \\times \\text {AVM} \\times \\text {ATM} \\times \\text {GDM} $$ MD(Main Damage) 主要攻击力【白字攻击力】主要攻击力 = 基础攻击力 + 主属性 除此之外，所有加成的攻击力都是【绿字攻击力】 PBD(Percentage bonus damage) 百分比攻击力加成这个加成是加法叠加 Tips: 圣者遗物可以增加60攻击力，一个出支配带头狼的VS，36%+30% = 66%，60 / 0.66 = 90，也就是说，白字攻击力达到90就等于这个英雄出了一个圣者遗物，相当的可怕。 技能 加成数值 头狼光环 30% 强化图腾 100%/200%/300%/400% 野性驱使 15%/26%/37%/48%（只影响狼人控制的单位） 授予力量 20%/30%/40%/50% (天赋 30%/40%/50%/60%) 神之力量 80%/120%/160% (友军A帐: 75%/100%/125%) 复仇光环 12%/20%/28%/36% (天赋 32%/40%/48%/56%) 祭品光环 15% FBD(Flat Bonus Damage) 固定值百分比加成 技能 加成数值 臂章-邪恶之力 31 嗜血渴望 最高攻击力加成/英雄: 16/24/32/40 战意 最高叠加层数: 5/7/9 每层攻击力加成: 18/24/30 极度饥渴 60/100/140 死亡契约 基于目标最大生命值的攻击力加成: 5%/7%/9% 精准光环 敏捷 20%/26%/32%/38% (天赋26%/32%/38%/44%) 星体游魂 小兵6/9/12/15 英雄 12/24/36/48 (天赋92/104/116/128) 灵动迅捷 10/25/40/55/70/85/100 A帐115 卡尔-火 4/8/12/16/20/24/28 * 3 决斗 10/14/18 (天赋50/54/58) 战斗嚎叫 70/100/130 月之祝福 14/22/30/38 嚎叫 英雄 10/15/20/25 非英雄 4/6/8/10 夜晚翻倍 静电连接 每秒偷取 7/14/21/28 (天赋21/28/35/42) 支配死灵 最大灵魂数: 18/24/30/36 (A帐 22/30/38/46) 折光 攻击次数: 3/4/5/6 (天赋6/7/8/9)攻击力加成: 20/40/60/80 魔化 20/40/60/80 长大 50/100/150 加主要攻击力 衰退光环 英雄死亡 30/35/40/45 小兵死亡 5 CSM(Critical Strike Multiplier) 致命一击倍数 致命一击来源 几率% 伤害% DPS期望% 头狼 - 致命一击 20 200 20 血棘 - 致命一击 20 175 15 酒仙 - 醉拳 10/15/20/25 230 13/19.5/26/32.5 混沌一击 12 125/175/225/275 3/9/15/21 水晶剑 - 致命一击 20 175 15 大炮 - 致命一击 30 235 40.5 剑舞 20/25/30/35 200% 20/25/30/35 狼人 - 变身 40 160/180/200 24/32/40 恩赐解脱 15 230/340/450 19.5/36/52.5 殊死一搏 15 英雄 150/200/250/300 7.5/15/22.5/30 血棘 - 灵魂撕裂 100 140 140 忍术 100 150/175/200/225 12/10/8/6 天赋 -5 棒击大地 100 150/175/200/225 天赋+100 触发条件 暗杀 100 A帐 280 距离内所有敌人 海象神拳 100 350/A帐500 冷却 36/24/12 游戏中出现的红字代表的是减少前的物理伤害 BD(Blocked Damage) 被格挡伤害 伤害格挡来源 几率% 格挡伤害 圆盾 50 近战16 远程8 穷鬼盾 英雄100 非英雄50 近战20 远程10 先锋盾 50 近战70 远程35 赤红甲 - 坚盾 100 60 海妖外壳 100 12/24/36/48 伤害格挡不格挡物理伤害技能，守卫的攻击也不格挡 AVM(Armor Value Multiplier) 护甲值倍数见护甲 ATM(Armor Type Multiplier) 护甲类型倍数见攻击类型，英雄打英雄100% GDM(General Damage Multipliers) 一般伤害倍数见伤害调整 攻击类型基础打英雄护甲75%伤害 穿刺打英雄护甲50%伤害，基础护甲（小兵护甲）150%伤害 伤害调整伤害减免和加深除了回光返照，幽灵船，魔法护盾之外，伤害减免和加深的叠加为加法叠加 技能 来源 数值% 血之狂暴 加深接受输出 25/30/35/40 远处 减半 赎罪 加深接受 18/24/30/36 灵魂猎手 加深接受 20/30/40/50 守卫冲刺 加深接受 15 血肉傀儡 加深接受 20/25/30 200范围内最高 回光返照 减免接受 0 全免 4/5/6 A帐+1 刚毛后背 减免接受 背后 16/24/32/40 侧面 减半 奔袭冲撞 减免接受 A帐 40 持续4秒 过载 减免接受 5/10/15/20 幽灵船 减免接受 40/45/50 持续10秒 决斗 减免接受 A帐 100 持续6/7/8秒 魔法护盾 减免接受 60 1.6/1.9/2.2/2.5 钻地 减免接受 40 折射 减免接受 10/14/18/22 激怒 减免接受 80 持续4秒 陵卫斗篷 减免接受 4层 8/12/16/20 冷却6/5/4/3 寒冬诅咒 减免接受 100 3.25/4/4.75 战斗饥渴 降低输出 A帐 30 持续10秒 白银之锋 降低输出 50 持续5秒 伤害无效化伤害实例仍然存在，如果一些与伤害触发相关的事件并且没有低于伤害阈值的伤害，仍然会触发伤害事件 技能或物品名称 说明 无天光盾 110/140/170/200 天赋 +300 15s持续时间 回光返照 3/4/5(A 5/6/7) 伤害转化为治疗 凝魂之类 5次 大于50点的伤害抵挡120点 尖刺外壳 2.25s持续时间 无效化每个玩家的第一次伤害 守护天使 6/7/8 (A 8/9/10) 物理伤害无效化 虚妄芝诺 7/8/9(天赋 +2) 持续时间结束受到被无效化的伤害 折光 次数 3/4/5/6(天赋 +3) 忽略低于5点的伤害 活体护甲 所有类型伤害无效化 20/40/60/80 次数 4/5/6/7(天赋 +4) 持续15s 低于5伤害忽略 极寒之拥 持续时间4s 无效物理伤害 攻击速度基础攻击间隔 BAT英雄在没有额外攻速加成的情况下每两次攻击间的时间间隔 攻击速度 ISA 面板中英雄增加的攻击速度 由装备获得的攻击速度加成 每个英雄基础100点基础攻速 由Debuff造成的攻速减低 攻击速度计算公式 $$ 每秒攻击的次数 = \\frac{(100 + IAS) × 0.01} {BAT} $$ $$ 每次攻击的时间 = \\frac{1}{每秒攻击的次数} $$ 攻击速度 效果 -80 五分之一BAT时间来攻击 -75 四分之一BAT时间来攻击 -66 三分之一BAT时间来攻击 -50 二分之一BAT时间来攻击 +00 正常状态 +100 * n （1+n）倍攻击速度 根据表格我们可以知道减攻速的技能在基础攻速很高的情况下基本没有什么效果，但是越接近0速度，减速效果越明显 增加攻击速度技能列表 技能 增加数值 持续时间s 魔霭诅咒 10/20/30/40 4.5 雷肤兽 - 暴怒 75 8 雷肤兽 - 战鼓光环 15 光环范围 900 天穹守望者 - 磁场 50/60/70/80 3.5/4.5/5.5/6.5 淘汰之刃 30 6 A帐10 成功淘汰 野性之心 15/25/35/45 光环范围 900 扫射 130 天赋 +70 4/6/8/10 熊怪 - 迅捷光环 15 光环范围 900 飓风之力 100 5 狂战士之血 220/260/300/340 剩下10%生命值最高 灵动迅捷 10/25/40/55/70/85/100/A115 9 卡尔 - 雷 2/4/6/8/10/12/14 * 3 开关 过载 40/50/60/70 开关 强攻 65/90/115/140 5 狂暴 50/60/70/80 3/4/5/6 炽魂 每层40/55/70/85(天赋 75/90/105/120) 10 最高3层 德鲁伊 - 狂猛 10/20/30/40 18/22/26/30 跳跃 16/32/48/64 (天赋 +100) 5 死灵射手光环 5/7/9 光环范围 900 暗夜猎影 45/60/75/90 夜晚 嗜血术 30/40/50/60 (天赋 +40) 30 幻影突袭 130 4s or 4次攻击 战斗专注 60/120/180 5 热血战魂 15/20/25/30 (105/140/175/210) 每次攻击同个目标 超强力量 400 15 or 3/4/5/6次攻击 黄泉颤抖 64 3/4/5/6 集中火力 500 20 寒冬诅咒 70 3.25/4/4.75 降低攻击速度技能比较有效果的降低攻速的技能 烈火精灵：80/100/120/140 不可侵犯：40/70/100/130，蝮蛇突袭：40/60/80 重生：75 黄泉颤抖：64 小狼-致残：60 冰封魔印：30/40/50/60 雷霆一击：25/35/45/55 原始咆哮：50 冰霜新星：20/30/40/50 液态火：20/30/40/50 石化凝视：50 夜魔虚空：50 冰眼：45 豪猪：10/20/30/40 冰火交加：28/32/36/40 毒龙法球：10/20/30/40 全能光环：10/18/26/34 技能攻击伤害技能伤害计算魔法伤害受到魔法抗性影响，技能伤害可以由智力获得增强 $$ 增强数值 = [初始智力 + (当前等级 - 1) \\times 智力成长] / 14 / 100 + 技能增强天赋 $$ $$ 技能最终伤害 = 技能伤害数值 \\times (1 + 增强数值) \\times \\\\ \\prod_{i=1}^n{(1 - 魔法抗性增加_i)} \\times\\prod_{i=1}^n{(1 + 魔法抗性降低_i)} $$ 技能增强天赋远古冰魄10：8% 蝙蝠骑士15：5% 人马20：10% 死亡先知10：5% 干扰者20：10% 大地之灵20：15% 灰烬之灵10：8% 矮人直升机10：6% 杰奇洛10：8% 拉西克20：5% 莉娜20：6% 莱恩20：8% 马格纳斯10：15% 米拉娜15：5% 食人魔魔法师25：15% 殁境神蚀者25：8% 凤凰20：8% 帕克20：10% 拉比克20：8% 暗影恶魔15：8% 影魔15：6% 风暴之灵25：10% 伐木机20：5% 修补匠15：4% 孽主15：12% 维萨吉25：20% 风行者20：15% 技能伤害类型分为：魔法伤害，物理伤害，纯粹伤害 大部分伤害为魔法伤害 物理伤害技能炼金术士：酸性喷雾 炼金术士：不稳定化合物 敌法师：法力损毁 斧王：反击螺旋 兽王：野性飞斧 赏金猎人：暗影步 钢背兽：针刺扫射 人马：反击 克林克兹：灼热之箭 戴泽：剧毒之触 戴泽：暗影波 死亡先知：驱使恶灵 主宰：无敌斩 昆卡：潮汐使者 拉西克：恶魔的赦令 噬魂鬼：盛宴 剃刀：风暴之眼 斯拉达：鱼人碎击 斯拉达：深海重击 狙击手：爆头 工程师：感应地雷 工程师：爆破起飞 潮汐猎人：锚机 熊战士：怒意狂击 冥界亚龙：幽冥剧毒 编织者：虫群 纯粹伤害技能祸乱之源：蚀脑 祸乱之源：噩梦 刃甲：反弹伤害 嗜血狂魔：血之祭祀 嗜血狂魔：割裂 陈：忠诚考验 死亡先知：吸魂巫术 末日使者：末日 魅惑魔女：推进 谜团：午夜凋零 祈求者：电磁脉冲 祈求者：阳炎冲击 莉娜：神灭斩A帐 美杜莎：石化后秘术异蛇 司夜刺客：尖刺外壳 全能骑士：洗礼 殁境神蚀者：奥术天球 帕吉：肉狗 痛苦女王：超声波冲击 沉默术士：智慧之刃 幽鬼：荒芜 圣堂刺客：灵能之刃 伐木机：锯齿飞轮 伐木机：伐木锯链 伐木机：带树木死亡旋风 修补匠：激光 骨灰 护甲白字护甲$$敏捷 = 基础敏捷 + (等级 - 1) * 敏捷成长$$ $$白字护甲 = 基础护甲 + ( \\frac{敏捷}{7})$$ 护甲值倍数$$护甲值倍数 = 1 - \\frac{0.06 \\times 护甲值}{1 + 0.06 \\times |护甲值| }$$ 护甲值倍数倍数和护甲值的相关曲线 相关曲线 纵坐标是护甲值倍数，横坐标是现在英雄的护甲，不同颜色的线是此时减少的护甲（越上面的线减的越多） 有效生命值 （EHP）有效生命值 = 总生命值 ÷ 护甲值倍数 $$ 实时有效物理生命值 = 当前生命值 \\div (1 - \\frac{0.06 \\times 当前总护甲值}{1 + 0.06 \\times |当前总护甲值| }) $$ $$ 实时有效魔法生命值 = 当前生命值 \\div (0.75 \\times (1 - 装备提供抗性_1) \\times \\ldots \\times (1 - 装备提供抗性_n)) $$ 护甲调整增加护甲的技能 技能 加成数值 持续时间s 黑龙 - 龙肤光环 3 光环范围 900 狂战士怒吼 40 2/2.4/2.8/3.2 编织 0.75/1.0/1.25 每秒 18/24/30 24 龙族血统 3/6/9/12(天赋 翻倍) 永久 霜冻护甲 3/5/7/9 40 战斗嚎叫 10/15/20 6 变形术 4/6/8 变形状态 寒冰盔甲 8 45 战吼 5/10/15/20 8 活性护甲 5/10/15/20 每层 1/1.2/1.4/1.6 10/13/16/19 崎岖外表 3/4/5/6 永久 巨魔 - 狂战士之怒 6 切换 减低护甲的技能 技能 降低数值 持续时间s 酸性喷雾 4/5/6/7 (天赋 +4) 16 远古 - 亵渎 50% 6 粘稠鼻液 1/1.4/1.8/2.2 最高层数4(8) 英雄5 小兵10 实相裂隙 3/4/5/6 8 编织 0.75/1/1.25每秒 (18/24/30) 24 自然秩序 基础护甲：40%/60%/80%/100% 光环范围 275 火人 - 攻击 每次1点 上限10 5 击中刷新时间 激流 2/3/4/5 8 范围 320 风暴之眼 0.7/0.6/0.5 (天赋 -0.1) 打击1次1点 30 魔王降临 3/4/5/6 光环范围 900 侵蚀雾霭 10/15/20 18 隐匿 2/4/6/8 10 巨浪 3/4/5/6 (天赋 +5) 4 死亡旋风 敏捷损失 * 0.14 14 恐怖波动 3/4/5/6 1400距离 300范围 15 虫群 1.4/1.25/1.1/0.95 攻击一次1点 16 护甲相关装备强袭 +5 玄冥盾牌系列 +2 勋章 +7 天鹰 +2 炎阳纹章 +10 祭品 +4 黯灭 -7 勋章 -7 炎阳纹章 -10 强袭 -5 枯萎之石 -2 疯脸 -5 闪避机制闪避与致盲都会在攻击完成（弹道击中）时有一定几率触发 叠加与计算多个闪避来源乘法叠加 上下坡落空几率如果攻击者处于比目标更低的位置时，远程攻击会有25%的几率落空。 攻击者和目标之间的地形的高低差异实在击中目标时决定的，中路对线过程中，可以使用弹道飞行过程位移来保持和目标的同样地形高度保证必中 飞行单位无上下坡落空几率 计算公式$\\prod_{i=0}^n$ 的含义是把i=0到n所有的项相乘 $$ 落空几率 = \\prod_{i=0}^n (1 - 闪避来源_i) \\times \\prod_{j=0}^n (1 - 致盲来源_j) \\times 上下坡落空几率 $$ $$ 命中几率 = 1 - \\prod_{i = 0}^n{(1 - 必中/克敌先机来源_i)} $$ $$ 最终命中几率 = 1 - 落空几率 \\times (1 - 命中几率) $$ $$ 最终落空几率 = 落空几率 \\times (1 - 命中几率) $$ 公式只是为了程序数值计算使用，是需要记住：每一次攻击要绕过所有的闪避成功命中，只有当所有的闪避都失败了，这次攻击才可以造成伤害。所以说，出很多个闪避装备，在一定程度上对物理核心非常克制，这时候物理核心必须出金箍棒 闪避来源 技能或物品名称 闪避几率% 敌法师 - 20级右天赋 15 磁场 100 3.5/4.5/5.5/6.5s 醉拳 10/15/20/25 一段时间的100%闪避 赏金猎人 - 25级右天赋 25 蝴蝶 35 人马 - 15级右天赋 10 克林克兹 - 20级右天赋 20 虚空 - 25级右天赋 20 黑暗贤者 - 10级右天赋 12 天堂之戟 25 噬魂鬼 - 20级右天赋 15 狼人 - 20级右天赋 15 美杜莎 - 15级左天赋 15 米波 - 20级右天赋 10 大圣 - 10级左天赋 12 模糊 20/30/40/50 猴子 - 20级左天赋 15 炎阳纹章 20 炎阳纹章- 队友使用 - 日耀 20 7s 斯温 - 20级左天赋 20 闪避护肤 20 圣堂刺客 - 15级左天赋 12 风行 100 3/4/5/6a 致盲来源 技能或物品名称 落空几率% 醉酒云雾 70 4s 麻痹之咬 30/40/50/60 2s 致盲之光 80 3/4/5s 伤残恐惧 白天10 3s 夜晚50 5/6/7/8s 辉耀 - 辉耀灼烧 17 烟雾 40/50/60/70 6s 激光 100 3/3.5/4/4.5s 小兵 6s 近战旋风飞斧 60 4/5/6/7s 克敌机先来源为一种攻击特效，防止该次攻击落空，用来反制闪避，致盲，以及远程单位上下坡的25%几率落空，也能够防止近战攻击由于目标在攻击之前超过了350距离而落空 但是攻击弹道依旧可以躲避 对建筑物无效 技能或物品名称 备注 不会落空为100% 强化图腾 带有Buff的一次攻击不会落空 棒击大地 不会落空的即时攻击 金箍棒 每次攻击带有克敌先机 复仇 破影一击不会落空 窒息之刃 不会落空的即时攻击 白银之锋 - 暗影步 破影一击不会落空 暗杀 需要A帐 自然庇护 破影一击不会落空 海象神拳！ 不会落空 死亡守卫 需要A帐 不会落空 必中来源必中防止一个单位受到的任何攻击落空 血棘的灵魂撕裂，岗哨守卫，炎阳纹章给敌方使用提供35%的必中效果 移动速度叠加相似的装备提供的移动速度不叠加，除了风帐 多个鞋类物品不叠加 夜叉 散夜对剑 幻影斧不叠加 多个战鼓或风灵之纹不叠加 风灵之纹和战鼓鞋类物品叠加 公式移动速度 = （基础移动速度 + 具体移动速度加成） * （1 + 百分比移动速度加成和减速的和） 魔法抗性魔法抗性除了米波35%，维萨吉10%魔法抗性外，其他英雄都为25%基础魔法抗性 魔法抗性乘法叠加，不同的提高魔法抗性的装备可以叠加 魔法抗性加成来源 技能或物品名称 加成数值%及备注 法术护盾 26/34/42/50 小马or小熊怪光环 英雄5 非英雄20 可叠加 魔抗斗篷 15 微光披风 15 被动 微光披风 - 微光 45 5s 0.6s渐隐时间 挑战头巾 25 狂战士之血 20/30/40/50 最大10%生命值 洞察烟斗 30 被动 洞察烟斗光环 10 腐肉堆积 6/8/10/12 失效力场 10/14/18/22 腐蚀皮肤 10/15/20/25 魔法抗性减少来源 技能或物品名称 减少数值% 备注 冰霜漩涡 15/20/25/30 16s 0.5s粘滞时间 自然秩序 40/60/80/100 光环范围350 1s粘滞时间 虚化冲击 40 敌方3s 友方4s 幽灵形态 40 4s 幽魂护罩 20 3/3.5/4/4.5 衰老 30/40/50/60 3.5 上古封印 30/35/40/45 3/4/5/6 纷争面纱 25 16 魔法抗性100%来源 技能或物品名称 备注 黑皇杖 10/9/8/7/6/5 牺牲 跳跃时间or持续5s 剑刃风暴 5s 狂暴 3/4/5/6 (天赋+1s) 石化凝视 3s 天赋5s 驱逐 4/5/6/7 命运赦令 3/3.5/4/4.5 魔法吸收护盾魔法吸收护盾计算是计算魔抗后的吸收数值，魔抗越高，护盾效果越好 任何类型魔法护盾无法叠加，同时吸收伤害 技能或物品名称 吸收数值 烈火罩 50/200/350/500 （天赋 +500） 挑战头巾 - 绝缘 325 持续12s 洞察烟斗 - 法术护盾 400 持续12s 物品被动效果叠加独立叠加 攻击力 属性加成 魔法值/生命值 生命恢复速率/魔法恢复速率（基础速率 * 加成倍数） 攻击速度加成 护甲加成 分裂区域 移动速度加成 乘法叠加出现边缘递减效应$$加成 = 1 - (1-x) \\times (1-y) \\times (1-z) \\times \\ldots$$其中 $x y z$ 都表示一个百分比 魔法抗性乘法叠加 一个100点魔法伤害的技能 英雄本身25%魔法抗性，伤害变为 100 * （1 - 25%） = 75 再装备挑战头巾，再降低30%，伤害变为 75 * （1 - 30%） = 52.5 躲避躲避是一种躲避弹道的行为，更确切的说，是使弹道完全失去跟踪目标能力的行为。白话文就是：秀操作，骚 躲避技能的方式技能以下技能在施法时能躲避弹道 炼金术士：化学狂暴 酒仙：元素分离 混沌骑士：混沌之军 噬魂鬼：感染``幻影斧：镜像 变体精灵：波浪形态 娜迦海妖：镜像 幻影长矛手：神行百变``凤凰：超新星 帕克：相位转移 力丸：绝杀秘技 风暴之灵：球状闪电 传送所有的真闪烁都能躲避弹道，躲避发生在使用技能移动时 敌法师：闪烁 闪烁匕首：闪烁 远行鞋：传送 艾欧：传送(只有艾欧传送过去时可以躲避) 先知：传送 帕克：灵动之翼 痛苦女王：闪烁 熊灵：回归 回城卷轴：传送 孽主：黑暗之门 编织者：时光倒流 陈：忠诚考验 光之守卫：召回 变体精灵：替换复制品 隐身所有能获得隐身状态的技能技能都能躲避弹道，除非敌人的在弹道到达之前使用了反隐，但是必须要注意不同技能的渐隐时间 隐藏变为临时性的隐藏不能躲避弹道。 躲避与变为隐藏无关，而是与技能本身有关。这意味着隐藏技能不一定都能躲避弹道， 但是，利用合适的时机，可阻止弹道或一般技能，击中施法者或目标。 隐藏来源有一下技能 酒仙：元素分离 混沌骑士：混沌之军 大地之灵：残炎魔咒 噬魂鬼：吸收 幻影斧：镜像 娜迦海妖：镜像 殁境神蚀者：星体禁锢 幻影长矛手：神行百变 凤凰：超新星 帕克：相位转移 力丸：绝杀秘技 暗影恶魔：崩裂禁锢 巨牙海民：雪球 无敌变为无敌不能躲避弹道，但是可以在击中时减轻或使其效果无效。 攻击伤害和技能伤害会被忽略。有一些技能可以影响无敌单位。 无敌来源 祸乱之源：噩梦 酒仙：元素分离 混沌骑士：混沌之军 大地之灵：残岩魔咒 灰烬之灵：无影拳 灰烬之灵：激活残焰 风帐：龙卷风 虚空假面：时间漫游 佣兽：石像形态 祈求者：强袭飓风 主宰：无敌斩 噬魂鬼：吸收 噬魂鬼：感染 幻影斧：镜像 变体精灵：波浪形态 娜迦海妖：镜像 娜迦海妖：海妖之歌 殁境神蚀者：星体禁锢 幻影长矛手：神行百变 凤凰：超新星 帕克：相位转移 力丸：绝杀秘技 暗影恶魔：崩裂禁锢 狂风：龙卷风 风暴之灵：球状闪电 巨牙海民：雪球 可以被躲避的弹道任何单位和英雄的所有物理攻击的弹道都可以躲避 可以被躲避的技能亚巴顿：迷雾缠绕 赏金猎人：投掷飞镖 酒仙：醉酒云雾 钢背兽：粘稠鼻涕 育母蜘蛛：孵化蜘蛛 混沌骑士：混乱之箭 陈：赎罪 戴泽：剧毒之触 龙骑士：神龙摆尾 大地：投掷巨石 撼地者：回音击 虚灵之刃：虚化冲击 变体精灵：变体攻击 泥土傀儡：投石 娜迦海妖：诱捕 食人魔魔法师：引燃 神谕者：气运之末 幻影刺客：窒息之刃 幻影长矛手：灵魂之矛 痛苦女王：暗影突袭 阿托斯：致残 天怒法师：震荡光弹 狙击手：暗杀 斯温：风暴之拳 潮汐猎人：巨浪 修补匠：导热飞弹 复仇之魂：魔法箭 冥界亚龙：蝮蛇突袭 维萨吉：灵魂超度 风行者：束缚击 寒冬飞龙：碎裂冲击 冥魂大帝：冥火暴击 不可以被躲避的技能炼金术士：不稳定化合物 天穹守望者：闪光幽魂 爱人直升机：追踪导弹 哈斯卡：牺牲 拉西克：闪电风暴 巫妖：连环霜冻 莉娜：神灭斩 莱恩：死亡一指 美杜莎：秘术异蛇 米拉娜：流星风暴 瘟疫法师：死亡脉冲 痛苦女王：痛苦尖叫 拉比克：技能窃取 天怒法师：奥法鹰隼 幽鬼：幽鬼之刃 小小：投掷 树精卫士：寄生种子 巨牙海民：雪球 寒冬飞龙：碎裂冲击弹射 巫医：麻痹药剂","tags":[{"name":"Dota2","slug":"Dota2","permalink":"https://charlesliuyx.github.io/tags/Dota2/"},{"name":"Data Analysis","slug":"Data-Analysis","permalink":"https://charlesliuyx.github.io/tags/Data-Analysis/"}]},{"title":"【直观详解】Logistic Regression","date":"2017-09-04T07:21:50.000Z","path":"2017/09/04/LogisticRegression学习笔记/","text":"【阅读时间】17min - 22min【内容简介】从不同角度解释为何使用Logistic回归模型，解读模型的现实意义，详细解读为何使用以及什么是交叉熵损失函数。并详细梳理符号表达，对公式不再恐惧 什么是【回归（Regression）】回归（Regression）是一项模拟技术，用来从一个或多个解释变量中预测输出变量的值 什么是及为什么【Logistic Regression】回归（Regression）是用来预测的，比如给你一组虫子的腿长和翅膀长数据，让你判断虫子是A类虫还是B类虫。 逻辑回归则是用来预测二进制输出变量取值（如：是/不是）的预测技术 即输出变量只有两个值得预测技术 下文中将会从不同的角度 概率论角度首先，需要回忆一下几个概念 【大数定理】 $$ \\lim_{n\\to\\infty} \\frac{1}{n} \\sum_{i=1}^n {X_i} = \\mu $$ 不断的采样一个随机变量，得到n个值，当n趋向于正无穷的时候，这个平均值就收敛于随机变量的期望 【中心极限定理】 大量相互独立{条件1}的随机变量，其均值的分布以正态分布{结论}为极限{条件2} 【贝叶斯公式】 默认你已经对条件概率了若指掌（在某件事情已经发生的情况下另一件事发生的概率），关于贝叶斯方法的前世今生，这个链接或许可以帮到你。 那贝叶斯公式是如何推出来的？ 问题描述我们需要求的问题是：你在校园里面随机游走，遇到了N个穿长裤的人（但是可能因为你高度近视你无法看出他们的性别），问，这N个人里面有多少个女生，多少个男生，即，穿裤子的人里面有多少个女生 解决过程 $$ 穿裤子的人中的女生比例 = \\frac{穿长裤的女生人数}{穿长裤的总人数} =\\\\ \\frac {U\\times P(Girl)\\times P(Paints|Girl)}{U\\times P(Boy)\\times P(Paints|Boy) + U\\times P(Girl)\\times P(Paints|Girl)}\\tag{1-1} $$ 化简上式，可以发现其实分母合起来就是 $P(Paints)$ ，分子其实就是既穿裤子又是女孩，整理得 $$ P(Girl|Paints) = \\frac{P(Girl) \\times P(Paints|Girl)}{P(Paints)} $$ 再一般化，用A表示穿裤子的，B表示女生$$P(B|A) = \\frac{P(B)\\times P(A|B)}{P(A)} = \\frac{P(AB)}{P(A)}\\tag{1-2}$$上式就是贝叶斯公式的一般形式，我们在推导中发现，正常人类对频率的感知和理解速度要高于对概率的。 比如“穿长裤的女生人数”这个概念，用总人数乘以女人比例，得出女生人数，再用女生人数乘以女生中穿裤子人数的比例得到穿裤子的女生人数。这一串推导感觉毫无困难。但如果读成：在A发生条件下，发成B的概率，会让人乍看下，感到有一定的理解困难。 我们常说Sense，我觉得这就是一种敏感，对条件概率表达方式的敏感，在你看到的时候，抓住那个最关键的点，不存在任何的迷惑 那Logistic Function和贝叶斯公式有什么联系呢？ 如果我们把公式（1-1）也符号化，$B_1$ 表示女生，$B_2$表示男生，$A$ 表示穿裤子$$P(B_1|A) = \\frac {P(B_1)P(A|B_1)}{P(B_2)P(A|B_2) + P(B_1)P(A|B_1)}\\tag{1-3}$$右边同时除以 $P(B_1)\\times P(A|B_1)$ ，并定义 $a = \\ln{\\left( \\frac{P(B_1)P(A|B_1)}{P(B_2)P(A|B_2)}\\right)}$ 直接由公式(1-3)可得到$$f(a) = \\frac{1}{1 + e^{-a}} \\tag{1-4}$$很熟悉的形式，其实就是logistic函数的一般形式（对数几率函数），而这个函数的值就是 $f(a)$ ，很明显，是一个概率 另一个很重要超级重要的常识就是：正态分布的的累计分布函数（就是从负无穷到x积分）和概率分布函数长得样子很像Logistic累计分布函数和概率密度函数，可能看到这句话很多人就已经真相大白了，应给无论从中心极限定理出发，还是从统计学概率论角度来看，概率分布存在的价值是为了描述自然界（现实）中的随机事件，构造函数本身就十分重要，不同的规律需要不同的函数去拟合 正太分布概率密度函数（左）累计密度函数（右） Logistic函数概率密度函数（左）累计密度函数（右） 统计学角度动机 - 需要解决什么问题在现实生活中，有时候需要探究某一事件 $A$ 发生的概率 $P$ （0 - 1 之间的一个数）与某些因素 $\\mathbf X = (X_1, X_2, \\ldots, X_p)’$ 之间的关系。（其中1到p是各种不同的因素） ☆ 【核心问题】考虑到很多情况下，$P$ 对 $\\mathbf X$ 的变化并不敏感，即 $\\mathbf X$ 需要发生很大的变化才能引起 $P$ 的微弱改变 比如，农药的用量和杀死害虫的概率之间，在农药用量在很小的范围内增长的时候，因为药效不够，杀死害虫的概率增长很慢。 因此，我们要构造一个关于 $P$ 的函数 $\\theta(P)$ ，使得它在 $P = 0$ 或 $P = 1$ 附近，$P$ 的微小变化对应 $\\theta(P)$ 的较大改变，同时，$\\theta(P)$ 要尽可能的简单。于是，我们可以构造一个函数（注意：构造函数是数学中很有效的手段，我们需要什么特性就用什么方法来构造一个满足我们需求的函数）c$$\\frac {\\partial \\theta(P)}{\\partial P} =\\frac{1}{P} +\\frac{1}{1-P}$$根据上述公式可以解得$$\\theta(P) =\\ln\\left(\\frac{P}{1-P}\\right)$$ 可视化 这个 $\\theta(P)​$ 就是Logit变换，可以看到，这个函数很符合我们的要求： $P = 0​$ 或 $P = 1​$ 附近，$P​$ 的微小变化对应 $\\theta(P)​$ 的较大改变 方案 - 如何解决这个问题为了建立因变量 $P$ 与自变量 $\\mathbf X$ 之间的合理变动关系，一个很自然的假设就是线性关系，也就是：$$P = \\mathbf X’ \\boldsymbol{\\beta}$$其中 $\\boldsymbol \\beta = (\\beta_1,\\beta_1,\\ldots,\\beta_p)$ 表示每一个不同因素对最终概率 $P$ 产生的影响（这个也可以写作，权重weight） 由需求可知，在某些情况下，$P = 0$ 或 $P = 1$ 附近，$P$ 对 $\\mathbf X$ 的变化并不敏感，简单的线性关系不能反映这一特征。此时，构造的 $\\theta(P)$ 就派上用场了$$\\ln\\left(\\frac{P}{1-P}\\right) = \\mathbf X’ \\boldsymbol{\\beta}$$进行一系列的公式推导有$$\\ln\\left(\\frac{P}{1-P}\\right) = \\mathbf X^\\mathrm T \\boldsymbol{\\beta} \\implies \\frac{P}{1-P} = e^{\\mathbf X^\\mathrm T \\boldsymbol{\\beta}} \\implies P = \\frac{e^{\\mathbf X^\\mathrm T \\boldsymbol{\\beta}}}{1 + e^{\\mathbf X^\\mathrm T \\boldsymbol{\\beta}}}$$则上述最后推出的就是Logistic回归模型 机器学习角度周志华《机器学习》，3.3 对数几率回归笔记 和统计学角度相同，我们的目的是依旧是完成一个二分类任务，输出标记 $y \\in {0,1}$ ，而线性回归模型产生的预测值 $z = \\boldsymbol w^{T}\\boldsymbol x + b$ 是实值，于是，我们需要把 z 转换为0/1值，最理想的是单位阶跃函数（unit-step function z &gt; 0➜y=1，z&lt;0➜y=1） 单单位阶跃函数不连续，不能微分，积分，求逆，于是我们希望找到能在一定程度上近似单位阶跃函数的替代函数（surrogate function），并希望它单调可微，答案很明显，就是对数几率函数（logistic function）$$y = \\frac{1}{1+e^{-z}}$$ z 为预测值，y 为输出，对数几率函数是一种Sigmoid函数【一种形状类似S的函数】，将$z = \\boldsymbol w^{T}\\boldsymbol x + b$ 带入上面的公式 $$y = \\frac{1}{1+e^{-(\\boldsymbol w^{T}\\boldsymbol x + b)}} \\implies \\ln(\\frac{y}{1-y}) = \\boldsymbol w^{T}\\boldsymbol x + b$$如果将 $y$ 作为 $\\mathbf x$ 作为正例的可能性，$1-y$ 为其反例的可能性$$\\frac {y}{1-y}$$上面的式子成为“几率”(odds)：表示 $\\mathbf x$ 是正例的相对可能性，对odds取对数得到“几率对数”(log odds，也就做logit) 生态学角度可以换一个角度来解读这个问题的前世今生 1798年的时候一个叫Malthus的英国牧师发现人口的变化率和人口的数目成正比，需要用数学的手法建立一个公式来表征这个现象，则，使用 $N(t)$ 这个函数来表示t时刻某个地区的总人口数（根据成正比）$$\\frac{dN(t)}{dt} = {rN(t)}$$ 其中，r是常数，表示 $N(t)$ 的变化率 直接解出这个方程$$N(t) = N_0e^{rt}$$这很明显是一个指数增长函数，其实也是种群增长的函数表示 但是问题也是很明显的：种群因为环境容量的限制一定是不能无限增长的，即，这个模型非常不靠谱，需要重新设计模型来复合现实中的情况。Pierre-François Verhulst 在1838年提出，构造一个函数$$\\frac{dN(t)}{dt} = {rN(t)}\\left(1 - \\frac{N(t)}{K}\\right)$$ K是一个常数，表示系统的容量（capacity） 令 $f(t) = \\frac{N(t)}{K}$ ，在方程两边同时除以 $K$ ，上述方程变为：$$\\frac{df(t)}{dt} = rf(1 - f)$$这也是Logistic方程的一般形式 总结从不同的角度来研究问题就会发现，其实很多时候我们解决一个问题具有一个相似的模式，包括大数定律，贝叶斯全概率公式是一切的基石和解决问题的主要工具 一个模型的建立规则依据数据的分布特征，而这里依托的一个关键信息就是：在靠近输入0，1两点的时候，y随x的变化不明显，线性模型没法很好的反应这个特征，所以就构造了一个逻辑回归模型来表示这个特征 并且Logistic回归模型的本质是一个概率模型，因为在描述该分类时，我们其实是以概率来衡量的 重要概念均方误差 Mean Squre Error MSE指参数估计值与参数真值之差平方的期望值，是一种目标函数（Objective Function），常用于线性回归$$MSE = \\frac{1}{n} \\sum_{t = 1}^n{(observed_t - predicted_t)}^2$$ 交叉熵 Cross Entropy又称为logloss，是Objective function的一种，也称Loss function or Coss Function 什么是熵我觉得这个问题必须搞明白一件事就是：什么是熵 Entropy 广义的定义是：熵是描述一个系统的无序程度的变量；同样的表述还有，熵是系统混乱度的度量，一切自发的不可逆过程都是从有序到无序的变化过程，向熵增的方向进行 有一个很神奇的解释是：熵字为火字旁加商。当时有位姓胡的学者作为普朗克的防疫。S(entropy)定义为热量Q与温度的比值，所以造字：熵 至于信息论上熵的概念更有意思，有兴趣可以转到 要理解这个Cross Entropy，必须了解它是用来干啥的？ 延伸：信息熵 交叉熵 相对熵的理解，需要跳转到另一篇笔记：什么是信息熵、交叉熵和相对熵 简单来说Cross Entropy可以表示可以度量最终训练结果于测试集的差异程度，MSE也是同样的作用。 换种更具体的说法：我们用p表示真实标记（训练样本标记）的分布，q是训练后的模型的预测标记（输出值标记）的分布，而交叉熵损失函数可以衡量p与q的相似性。 似然函数定义：给定联合样本值 $x$ 关于（未知 - 因为也是一边的自变量）参数 $\\theta$ 的函数$$L(\\theta|x) = f(x;\\theta)$$ $x$ 指联合样本随机变量 $X$ 取到的值，比如天气取值 $X$ =【晴，阴，雨，雪】$x$ = 晴 $\\theta$ 指未知参数，属于参数空间，比如正态分布的均值，方差等 $f(x;\\theta)$ 是密度函数，表示 $\\theta$ 参数下联合样本值 $x$ 的联合密度函数（所以这里不用|符号，|符号表达的意思是条件概率或条件分布） 从定义上，似然函数和密度函数是完全不同的两个数学对象：前者是关于 $\\theta$ 的函数，后者是关于 $x$ 的函数。中间的等号理解成函数值形式相等 这个等式表示的是对于事件发生的两种角度的看法。左边表示概率，右边表示可能性。要表达的含义都是：给定一个样本 $x$ 后，我们去测度这个样本出现的可能性到底有多大。说人话，比如样本空间是 $X =【晴，阴，雨，雪】$，函数表达的就是样本 $x$ = 晴在这个样本空间下发生的概率或可能性 从统计学的角度来说，这个样本的出现一定是基于一个分布的（比如二项分布，只正态分布等等），那么我们假设这个分布为 $f(x;\\theta)$ ，对于不同的 $\\theta$ 样本的分布不一样。 $f(x;\\theta)$ 函数表示的就是在参数 $\\theta$ 下 $x$ 出现的概率有多大（可以带入天气例子思考） $L(\\theta|x)$ 表示在给定样本 $x$ ，哪个参数 $\\theta$ 使得 $x$ 出现的可能性有多大。说人话，我们已经知道天气是晴天，哪个参数（可能是 $\\theta_1$ $\\theta_2$）使得这个函数值最大 对于Logistic Regression 为什么要用LogLoss - Cross Entropy了解了熵，和似然函数，我们可以开始看看在Logistic Regression的条件下为什么要用LogLoss，换句话也就是说，它一定有它的优势，我们采用，那么它有什么优势？ Logistic Regression的本质还是一个二分类问题，即Y = 0，or Y = 1 令 $P(Y=1|x) = \\pi(x)$ $P(Y=1|x) = 1 - \\pi(x)$ $y_i$ 表示i次试验，取值就是0 or 1（二分类问题） $\\pi(x) = \\frac{1}{1 + e^{-wx}}$ 是Logistic Function的表现形式，其中w相当于似然函数一节提到的 $\\theta$ 是需要求的参数（加深理解，其实在二分类问题中，Logistic函数就是一种形式上的概率分布的表现形式） 所以使用基本概率方法可以求解二分类的问题的似然函数 $$ \\ell(w) = \\prod_{i = 1}^{N} [\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i} $$ 注解：说白就和算扔N次硬币，一个连续正反事件串的概率是多少一个含义 看到乘法和指数，第一反应取对数，得到对数似然函数$$L(w) = \\sum_{i=1}^N{[y_ilog_a\\pi(x_i) + (1-y_i)log_a(1-\\pi(x_i))]}$$ 如果跟随我的步伐走到这一步，你会发现，这个形式，前半部分是“正例成立”的交叉熵，后半部是“反例成立”的交叉熵，说实话，叫做交叉熵和二项分布，伯努利过程分不开联系。在上面不远的地方已经详细定义了这几个符号代表的意思 我们发现，$-\\frac{L(w)}{N}$ 就是我们一直使用的Objective function or Loss Function or Cost Function（加负号才是最终的形式）。总之，训练的目的就是要求能够使得这个函数达到最小的参数，最终的目的还是计算出模型参数，就是 $w$ ，这个参数在上方的统计学角度，和机器学习角度都进行的讨论，重复阅读可以链接这些知识点 至于LogLoss的好处，一是取对数之后，乘法边加法，指数放下来，是凸函数，方便可以寻找最优解。二是加快了收敛速度，这里有个形象的步长比喻，可以想象成去了对数后，缩小了尺度，可以让最快梯度下降法要走的距离变短","tags":[{"name":"BitTiger","slug":"BitTiger","permalink":"https://charlesliuyx.github.io/tags/BitTiger/"},{"name":"Theory","slug":"Theory","permalink":"https://charlesliuyx.github.io/tags/Theory/"},{"name":"Model","slug":"Model","permalink":"https://charlesliuyx.github.io/tags/Model/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://charlesliuyx.github.io/tags/Machine-Learning/"}]},{"title":"Xpath使用指南","date":"2017-08-28T19:00:33.000Z","path":"2017/08/28/Xpath使用指南/","text":"【阅读时间】查阅类文档【内容简介】Xpath相关使用法法和例子文档，以供查阅（➜ 后是对应语句的输出output） XPath 相关例子Note例子1123456789101112131415from lxml import etreesample1 = \"\"\"&lt;html&gt; &lt;head&gt; &lt;title&gt;My page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;Welcome to my &lt;a href=\"#\" src=\"x\"&gt;page&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;This is the first paragraph.&lt;/p&gt; &lt;!-- this is the end --&gt; &lt;/body&gt;&lt;/html&gt;\"\"\"def getxpath(html): return etree.HTML(html)s1 = getxpath(sample1) //绝对路径 text() 获取内容中的文字信息1s1.xpath('//title/text()') ➜ ['My page'] / 相对路径1s1.xpath('/html/head/title/text()') ➜ ['My page'] 获取属性src的值1s1.xpath('//h2/a/@src') ➜ ['x'] 获取所有属性href的值1s1.xpath('//@href') ➜ ['#'] 获取网页中的所有文本123456789101112131415s1.xpath('//text()')➜['\\n ', '\\n ', 'My page', '\\n ', '\\n ', '\\n ', 'Welcome to my ', 'page', '\\n ', 'This is the first paragraph.', '\\n ', '\\n ', '\\n'] 获取网页中的所有注释1s1.xpath('//comment()') ➜ [&lt;!-- this is the end --&gt;] 例子212345678910111213sample2 = \"\"\"&lt;html&gt; &lt;body&gt; &lt;ul&gt; &lt;li&gt;Quote 1&lt;/li&gt; &lt;li&gt;Quote 2 with &lt;a href=\"...\"&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quote 3 with &lt;a href=\"...\"&gt;another link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;h2&gt;Quote 4 title&lt;/h2&gt;Something here.&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt;&lt;/html&gt;\"\"\"s2 = getxpath(sample2) 获取所有li中的文本1s2.xpath('//li/text()') ➜ ['Quote 1', 'Quote 2 with ', 'Quote 3 with ', 'Something here.'] 获取第一个 第二个li中的文本，两种写法均可1s2.xpath('//li[position() = 1]/text()') ➜ ['Quote 1'] 1s2.xpath('//li[1]/text()') ➜ ['Quote 1'] 1s2.xpath('//li[position() = 2]/text()') ➜ ['Quote 2 with '] 1s2.xpath('//li[2]/text()') ➜ ['Quote 2 with '] 奇数 偶数 最后一个1s2.xpath('//li[position() mod2 = 1]/text()') ➜ ['Quote 1', 'Quote 3 with '] 1s2.xpath('//li[position() mod2 = 0]/text()') ➜ ['Quote 2 with ', 'Something here.'] 1s2.xpath('//li[last()]/text()') ➜ ['Something here.'] li下面a中的文本1s2.xpath('//li[a]/text()') ➜ ['Quote 2 with ', 'Quote 3 with '] li下a或者h2的文本1s2.xpath('//li[a or h2]/text()') ➜ ['Quote 2 with ', 'Quote 3 with ', 'Something here.'] 使用 | 同时获取 a 和 h2 中的内容1s2.xpath('//a/text()|//h2/text()') ➜ ['link', 'another link', 'Quote 4 title'] 例子312345678910111213sample3 = \"\"\"&lt;html&gt; &lt;body&gt; &lt;ul&gt; &lt;li id=\"begin\"&gt;&lt;a href=\"https://scrapy.org\"&gt;Scrapy&lt;/a&gt;begin&lt;/li&gt; &lt;li&gt;&lt;a href=\"https://scrapinghub.com\"&gt;Scrapinghub&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"https://blog.scrapinghub.com\"&gt;Scrapinghub Blog&lt;/a&gt;&lt;/li&gt; &lt;li id=\"end\"&gt;&lt;a href=\"http://quotes.toscrape.com\"&gt;Quotes To Scrape&lt;/a&gt;end&lt;/li&gt; &lt;li data-xxxx=\"end\" abc=\"abc\"&gt;&lt;a href=\"http://quotes.toscrape.com\"&gt;Quotes To Scrape&lt;/a&gt;end&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt;&lt;/html&gt;\"\"\"s3 = getxpath(sample3) 获取 a 标签下 href 以https开始的1s3.xpath('//a[starts-with(@href, \"https\")]/text()') ➜ ['Scrapy', 'Scrapinghub', 'Scrapinghub Blog'] 获取 href=https://scrapy.org1s3.xpath('//li/a[@href=\"https://scrapy.org\"]/text()') ➜ ['Scrapy'] 获取 id = begin1s3.xpath('//li[@id=\"begin\"]/text()') ➜ ['begin'] 获取text = Scrapinghub1s3.xpath('//li/a[text()=\"Scrapinghub\"]/text()') ➜ ['Scrapinghub'] 获取某个标签下 某个参数 = xx1s3.xpath('//li[@data-xxxx=\"end\"]/text()') ➜ ['end'] 1s3.xpath('//li[@abc=\"abc\"]/text()') ➜ ['end'] 例子41234567891011121314151617181920212223sample4 = u\"\"\"&lt;html&gt; &lt;head&gt; &lt;title&gt;My page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;Welcome to my &lt;a href=\"#\" src=\"x\"&gt;page&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;This is the first paragraph.&lt;/p&gt; &lt;p class=\"test\"&gt; 编程语言&lt;a href=\"#\"&gt;python&lt;/a&gt; &lt;img src=\"#\" alt=\"test\"/&gt;javascript &lt;a href=\"#\"&gt;&lt;strong&gt;C#&lt;/strong&gt;JAVA&lt;/a&gt; &lt;/p&gt; &lt;p class=\"content-a\"&gt;a&lt;/p&gt; &lt;p class=\"content-b\"&gt;b&lt;/p&gt; &lt;p class=\"content-c\"&gt;c&lt;/p&gt; &lt;p class=\"content-d\"&gt;d&lt;/p&gt; &lt;p class=\"econtent-e\"&gt;e&lt;/p&gt; &lt;!-- this is the end --&gt; &lt;/body&gt;&lt;/html&gt;\"\"\"s4 = etree.HTML(sample4) 获取 class = test 标签中的所有文字12s4.xpath('//p[@class=\"test\"]/text()')➜ ['\\n 编程语言', '\\n ', 'javascript\\n ', '\\n '] 使用String来获得文字段； strip() 移除字符串收尾字符，默认为空格12345print (s4.xpath('string(//p[@class=\"test\"])').strip())➜编程语言python javascript C#JAVA 获取所有class属性中以content开始的1s4.xpath('//p[starts-with(@class,\"content\")]/text()') ➜ ['a', 'b', 'c', 'd'] 获取所有class属性中包含content的1s4.xpath(('//*[contains(@class,\"content\")]/text()')) ➜ ['a', 'b', 'c', 'd', 'e']","tags":[{"name":"crawl","slug":"crawl","permalink":"https://charlesliuyx.github.io/tags/crawl/"}]},{"title":"PDF复制粘贴去除多余的回车符","date":"2017-07-30T06:03:08.000Z","path":"2017/07/29/PDF复制粘贴去除多余的回车符/","text":"直接上解决步骤，但是只能适用于Windows平台，Mac这边可以尝试用Alfred + workflow来对剪切板操作来解决，或者用BetterTouchTool的自带个性化功能来尝试。只是一个思路，没有在Mac系统尝试 下载 Autohotkey ，安装（这一步都卡住那估计救不了了） 桌面右键 ➜ 新建 ➜ 创建新的AutoHotkey Script 右键创建的文件 ➜ 选择 Edit Script 出来一个记事本 编辑记事本文件，在已经有的内容下直接加上 1234567891011121314151617#IfWinActive ahk_class classFoxitReader^c:: old := ClipboardAll clipboard := &quot;&quot; send ^c clipwait 0.1 if clipboard = clipboard := old else &#123; tmp := RegExReplace(clipboard, &quot;(\\S.*?)\\R(.*?\\S)&quot;, &quot;$1 $2&quot;) clipboard := tmp StringReplace clipboard, clipboard, % &quot; &quot;, % &quot; &quot;, A clipwait 0.1 &#125; old := &quot;&quot; tmp := &quot;&quot;return 这里有个问题 IfWinActive ahk_class classFoxitReader 第一行的classFoxitReader 是指的你用什么程序打开PDF 如果是FoxitReader就是classFoxitReader 如果是Acrobat Adobe就是AcrobatSDIWindow 可以用Autohotkey中的 WinGetClass 来获得某一个窗口的ahk_class 保存退出 桌面上双击你刚刚编辑的文件，可以看到右下角出现了一个H形状的图标 大功告成，这时候你再试试去PDF文档里面ctrl + c就没有回车符了（当然，段落还是无法区分的），也不一定，这一段既然是脚本语言，那就有无限的可能性，就看你的算法实现能力了对吧！","tags":[{"name":"Tools","slug":"Tools","permalink":"https://charlesliuyx.github.io/tags/Tools/"},{"name":"Autohotkey","slug":"Autohotkey","permalink":"https://charlesliuyx.github.io/tags/Autohotkey/"}]},{"title":"LeetcodeNote","date":"2017-07-01T07:18:41.000Z","path":"2017/07/01/LeetcodeNote/","text":"算法培训课程基本模型汇总笔记 线基本模型数学归纳法树基本模板 Draw/Equation -&gt; Tree shape Define TreeNode 本点信息必然是辅助变量，计入TreeNode 孩子信息决定TreeNode的形状 任何第一次走的节点，如果不能走，一定要画出来打一把叉 Binary Search123456789101112131415Public int func(T[] array, V tartget )&#123; int pos = -1; int start = 0; int end array.length - 1; while ( start &lt;= end )&#123; int mid = start + (end - start)/2; if ( f(a[mid]) &lt;= target )&#123; pos = mid; start = mid + 1; &#125; else &#123; end = mid - 1; &#125; &#125; return pos;&#125; Bottom up - Recursion123456789101112131415public &lt;T_P&gt; func(T_v_1, v1 …)&#123; checkhastreeNode(); return helper(root(T_v_1, v_1, …))&#125;private &lt;T_P&gt; helper(T_v_1, v1, …)&#123; resultchildfirst = helper(childFirst); … resultchildlast = helper(childLast); -&gt; result by childs //generate cur node's result; return result;&#125; DFS12345678910111213141516171819202122232425262728public class DFSTree &#123; public Type_R func(T_1, e1, T_2, e2)&#123; checkrootexists(); TreeNode[] array = new TreeNode[TREE_HEIGHT]; Stack&lt;TreeNode&gt; stack = Stack&lt;&gt;(); stack.push(root); while (!stack.Empty())&#123; TreeNode curNode = stack.pop(); Operation at node; stack.push(childLast); … stack.push(childFirst); &#125; return result; &#125; private class TreeNode&#123; T_V_1 field_1; … T_V_q field_q; int _height; &#125; BFS1234567891011121314151617181920212223242526272829303132public class BFS &#123; public TypeR func(T_1 v_1, T_p, v_p) &#123; checkexistroot(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while ( !queue.isEmpty() )&#123; int size = queue.size(); for ( int I = 0; I &lt; size; i++ )&#123; TreeNode node = queue.remove(); op at node; queue.add(childFirst); … queue.add(childLast); &#125; update var_l,…,var_k for next level &#125; return result; &#125; private class TreeNode&#123; T_1 field_1; … &#125;&#125; 图基本模板","tags":[{"name":"算法","slug":"算法","permalink":"https://charlesliuyx.github.io/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://charlesliuyx.github.io/tags/Leetcode/"}]},{"title":"幕布-全平台笔记思维导图工具","date":"2017-06-17T17:30:47.000Z","path":"2017/06/17/幕布-全平台笔记思维导图工具/","text":"利益相关：幕布深度使用用户 向大家强烈自来水一款从知乎上了解到的效率神器：幕布，简直相见恨晚，自从它4月正式上线后就一直使用，对我的日常生活、学习和计划帮助巨大（个人情况：硕士CE在读，ML方向，效率至上主义者，简约UI风格拥护者） 幕布是一款思维管理工具，可以用来做笔记，梳理思路，做待办事项等等等等。 人类的记忆是有缺陷的，计算机能帮助人进行记忆。我们可以记住大方向的条目，再借助一个笔记软件来唤起我们的记忆。树形结构是一种极为高效的模式及手段。 笔记软件很多，思维导图软件很多，但是能同时满足以下几点的我找了很久都没有找到，直到遇到幕布。如果你和我也有同样的需求，真心的希望这款优秀的软件能帮助到你，提高的你的日常效率，让每一次阅读，每一个计划都高效落地 UI简约，专注于层次输入本身幕布的官网是这样的： 幕布官网 幕布作为一款笔记软件编辑界面是这样的，幕布专注于层次化输入，每一个输入对于幕布来说都是一个条目，条目就是我们进行知识梳理的主干 幕布编辑界面 每一个操作都提倡使用快捷键，拒绝鼠标 + 键盘混用带来的输入思路打断的低效率 幕布快捷键页面 全平台，云存储和同步，客户端离线编辑答主因为同时使用各种设备：12.9寸iPad，Mac，Windows + Linux 台式机和iPhone手机几个工作平台，平常使用电脑进行笔记记录，碎片化时间使用个手机进行背诵记忆等，需要一款全平台的笔记软件。 而幕布，只要有浏览器，有网络就能流畅使用，有离线需求的用户，也可以通过客户端的形式满足日常编辑的需求。 幕布全平台 一键生成思维导图选择幕布的重要理由之一，废话不多说，上Gif！ 幕布快捷键页面 用过各种软件，Coggle是UI最漂亮的，但是基本的演示需求幕布完全可以满足，清楚明了 那么话说回来了，幕布可以用来干什么呢？下面就展示几个主要应用场景（有我自己的，也有来自于幕布使用趣味案例） 首先，官网给出了一份幕布产品引导，其中详细介绍了幕布的使用场景 读书笔记 方案计划 流程说明 等等 下面案例一些答主自己日常的一些特殊使用场景，基本应用比如做笔记，待办事项，做日程规划等不一一列出来了，就是基本的笔记需求。 TED演讲笔记没有遇到幕布之前，我经常看TED的各种演讲，用于开拓视野，进行英语表达的积累，做笔记的速度太慢，太不方便，遇到幕布之后，我将TED的视频中很关键的内容记录成幕布的条目层次，之后利用碎片化的时间使用手机客户端进行记忆和背诵，极大的丰富了我的谈资（记住的东西才能侃，有条理有依据的说辞才有说服力） 埃里克 哈世延：下一个科学界大突破是什么 对于这个TED笔记例子 演讲人大体思路 经典的单句和例子（中英文） 另一方面，因为幕布的全平台特性，我会用碎片化的时间利用电脑端的幕布来进行背诵（TED的演讲内容对于积累对应领域的英文表达方式有很大的帮助） 程序设计和Presentation编程前先走流程和功能设计是我平时的习惯，这里有一个很简单的Server-Client模式的练习设计用法：设计程序功能，直接一键思维导图展示，PPT完全不用做了，非常愉悦 程序Feature Dota2 Wiki在国外我发现Dota2维基十分的给力，作为Dota2玩家有一些施法距离，施法机制等有时候需要查看（进阶），但是使用网站一方面内容太多，国内访问实在太慢了，而且搜索功能也做的不好，至于我做了什么事情，各位看gif自行感受 Dota2 【利益相关：正在制作，预计Ti7前可以上线，希望也能通过数据帮助到中国军团吧，作为一个做计算机的程序员也希望贡献自己的一份力量】 期末考试复习幕布可以帮助我们把书读薄，我们知道所有的书的特点就是具有层次化，每一本非常优秀的教材都有一套自己对于本学科的知识体系的理解和层次化抽象，之前我进行期末复习需要的时间大概是7天左右，有了幕布可以把时间缩减为3天或者更短 期末复习笔记总览 期末复习笔记具体内容 幕布精选在幕布里，学习知乎模式，你也可以分享自己中意的作品，获得点赞，在后面讨论，甚至有打赏功能，因为软件本身还很年轻，一切还在发展阶段，对于我本人来说，幕布精选的内容只是锦上添花，我个人不太需求这个功能，但是其中还有一份驾考总结挺有用的，哈哈 幕布精选 幕布精选打赏功能 总结和杂七杂八我现在的习惯是，只要是读微信公众号的文章，做笔记，读书等，都会用幕布进行记录和整理，感觉提升效率十分明显（节省了我30-40%左右的时间，每天） 幕布提高我的三个能力 整理和总结的能力【如何把书读薄】 层次化思维能力【有组织的整理自己的知识体系和思路模式，加强效率，节省时间】 背诵能力【全平台（手机），我对碎片化时间能有效利用，我可以多次重复背诵需要背诵的内容】 最后，谢谢你阅读本答案到这个位置，对于我来说，幕布这种层次化的思维模式解决了我当年考高考时候的问题：什么学习方法是最好的？我觉得幕布的层次化整理知识的能力就是答案，幕布提供的是一张纸，一支笔，最后使用幕布能把你的学习生活提升到什么程度，完全取决于你的能力本身，幕布只是工具，帮助你整理你的大脑，帮你进行背诵，方便查阅。 工具永远是工作，创造效益的永远是你，未来也是人创造的，不是工具。 【利益相关，使用我的幕布分享链接可以获得15天的免费高级版试用机会，跪求点击注册！hohohohoho】 我的分享链接 幕布，绝对是一个神器，希望能帮助到各位，提升效率，创造更大的价值！","tags":[{"name":"效率工具","slug":"效率工具","permalink":"https://charlesliuyx.github.io/tags/效率工具/"},{"name":"幕布","slug":"幕布","permalink":"https://charlesliuyx.github.io/tags/幕布/"}]},{"title":"深入浅出看懂AlphaGo如何下棋","date":"2017-05-27T18:51:22.000Z","path":"2017/05/27/AlphaGo运行原理解析/","text":"问题分析围棋问题，棋盘 19 * 19 = 361 个交叉点可供落子，每个点三种状态，白（用1表示），黑（用-1表示），无子（用0表示），用 $\\vec s$ 描述此时棋盘的状态，即棋盘的状态向量记为 $ \\vec s$ （state首字母）。 $$\\vec s = (\\underbrace{1,0,-1,\\ldots}_{\\text{361}})\\tag {1-1}$$假设状态 $\\vec s$ 下，暂不考虑不能落子的情况， 那么下一步可走的位置空间也是361个。将下一步的落子行动也用一个361维的向量来表示，记为 $\\vec a$ （action首字母）。$$\\vec a = (0,\\ldots,0,1,0,\\ldots)\\tag {1-2}$$公式1.2 假设其中1在向量中位置为39，则 $\\vec a$ 表示在棋盘(3,1)位置落白子，3为横坐标，1为列坐标 有以上定义，我们就把围棋问题转化为。 任意给定一个状态 $\\vec s$ ，寻找最优的应对策略 $\\vec a$ ，最终可以获得棋盘上的最大地盘 总之 看到 $\\vec s$ ，脑海中就是一个棋盘，上面有很多黑白子 看到 $\\vec a$ ，脑海中就想象一个人潇洒的落子 接下来的问题是，如何解决这样一个问题呢？ 先上论文！干货第一 Mastering the game of Go with deep neural networks and tree search 问题解决首先想到，棋盘也是一幅图像，那么在当时最好用的图像处理算法就是深度卷积神经网络（Deep Convolutional Neural Network）。 深度卷积神经网络——策略函数（Policy Network）关于什么是CNN，这篇文章十分靠谱，深入浅出的讲解了什么是CNN An Intuitive Explanation of Convolutional Neural Networks （好像原地址挂了）（5.29更新，原地址已经恢复，原地址的排版更好，估计之前那个博主在进行博客的整理） 大致可以理解为： CNN例子 对一副图像进行处理，给定很多样本进行训练，使得最后的神经网络可以获得指定（具有分类效果）的输出。 比如，根据上图可以观察到（这是一个已经训练好的神经网络），最右侧的输出是[0.01 , 0.04 , 0.94 , 0.02]，其中第三个值0.94代表的是boat，接近1，所以我们判断这幅图片中有船这个物体（类似的，如果使用这幅图像进行训练，那么指定输出应该是[0, 0, 1, 0]，因为图中只有船这个物体） 在Deep Learning中，卷积层的中的Filter也需要训练，也就是说我们使用已有数据来学习图像的关键特征，这样，就可以把网络的规模大幅度的降低 总而言之，CNN可以帮助我们提取出图像中有实际含义的特征，那么这和围棋又有什么关系呢？我们来看看Deepmind团队是怎么运用CNN来解决围棋问题。 深度卷积神经网络解决围棋问题2015年，Aja Huang在ICLR的论文Move Evaluation in Go Using Deep Convolutional Neural Networks中就提出了如何使用CNN来解决围棋问题。 他从围棋对战平台KGS上获得了人类选手的围棋对弈棋谱，对于每一个状态 $ \\vec s$，都会有一个人类进行 $ \\vec a$ 的落子，这也就是一个天然训练样本 $ \\langle \\vec s,\\vec a\\rangle $，如此可以得到3000万个训练样本。 之后，将 $ \\vec s$ 看做一个19*19的二维图像（具体实现依据论文输入数据是19*19*48（48是这个位置的其他信息，比如气等信息，激励函数用的 tanh）使用CNN进行训练，目标函数就是人类落子向量 ${\\vec a}’$，通过使用海量的数据，不断让计算机接近人类落子的位置。就可以得到一个模拟人类棋手下棋的神经网络。 使用训练的结果，我们可以得到一个神经网络用来计算对于每一个当前棋盘状态 $ \\vec s$ ，所对应的落子向量 $ \\vec a$ 的概率分布（之所以是概率分布，是因为，计算好的神经网络，输出一般是一个0-1之间的浮点数，越接近1的点表示在这个位置越接近人类的风格，也可以等同于作为人类概率最大的落点。$$\\vec a=f(\\vec s) \\tag{2-1}$$根据公式2.1，我们记 $f()$ 为$P_{human}(\\vec s)$ ，论文中也叫做Policy Network，也称策略函数。表示的含义是 在状态 $\\vec s$ 下，进行哪一个落子 $\\vec a$ 是最接近人类风格的 计算出来的直观结果，对应到棋盘上如下图，可以看到，红色的区域的值有60%，次大值位于右方，是35%（此图来自于AlphaGo论文） Policy Network 还记得刚刚举得船图的例子嘛？可以类比一下，机器发现现在的状态 $ \\vec s$ 和之前的某一种类型有些类似，输出是一个1*361的向量，其中有几个值比较大（接近1就是100%），那么就用这个值当做下一个 $ \\vec a$ 的位置。不幸的，这种训练方法有很大的局限的，可以直观想到的是，如果对战平台上数据本身就都是俗手，那不是训练出来一个很蠢的神经网络嘛？棋力如何呢？ 深度卷积网络策略的棋力很不幸，据Aja Huang本人说，这个网络的棋力大概相当于业余6段所有的的人类选手。远远未能超过当时最强的围棋电脑程序CrazyStone。 既然比不过，那么就学习它，Aja Huang打算把 $P_{human}(\\vec s)$ 和CrazyStone结合一下，那么问题就来了， CrazyStone是怎么来解决围棋问题的呢？ 这是Aja Huang的老师Remi Colulum在2006年对围棋AI做出的另一大重要突破 干货论文送上 MCTS Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search MCTS 蒙特卡洛搜索树——走子演算（Rollout）蒙特卡洛搜索树（Monte-Carlo Tree Search）是一种大智若愚的方法，它的基本思想是： 首先模拟一盘对决，使用的思路很简单，随机 面对一个空白棋盘 $\\vec s_0$，最初我们对棋盘一无所知，假设所有落子的方法分值都相等，设为1 之后，【随机】从361种方法中选一种走法 $\\vec a_0$，在这一步后，棋盘状态变为 $\\vec s_1$。之后假设对方也和自己一样，【随机】走了一步，此时棋盘状态变为 $\\vec s_2$ 重复以上步骤直到 $\\vec s_n$并且双方分出胜负，此时便完整的模拟完了一盘棋，我们假设一个变量r，胜利记为1，失败则为0 那么问题就来了，如果这一盘赢了，那意味着这一连串的下法至少比对面那个二逼要明智一些，毕竟我最后赢了，那么我把这次落子方法 $(\\vec s_0, \\vec a_0)$ 记下来，并把它的分值变化：$$\\text{新分数} = \\text{初始分数} + r \\tag{2-2}$$同理，可以把之后所有随机出来的落子方法 $(\\vec s_i, \\vec a_i)$ 都应用2-2公式，即都加1分。之后开始第二次模拟，这一次，我们对棋盘不是一无所知了，至少在 $\\vec s_0$ 状态我们知道落子方法 $\\vec a_0$ 的分值是2，其他都是1，我们使用这个数据的方法是：在这次随机中，我们随机到 $\\vec a_0$ 状态的概率要比其他方法高一点。 之后，我们不断重复以上步骤，这样，那些看起来不错（以最后的胜负来作为判断依据）的落子方案的分数就会越来越高，并且这些落子方案也是比较有前途的，会被更多的选择。 $$ score(\\vec s) = \\begin{pmatrix} r_{11} & r_{12} & \\cdots & r_{1n} \\\\ r_{21} & r_{22} & \\cdots & r_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ r_{n1} & r_{n2} & \\cdots & r_{nn} \\end{pmatrix} $$ 如上述公式所述，n=19，每一个状态 $\\vec s$ 都有一个对应的每个落子点的分数，只要模拟量足够多，那么可以覆盖到的 $\\vec s$ 状态就越多，漏洞就越来越小（可以思考李世石的神之一手，是否触及到了AlphaGo1.0的软肋呢？即没有考虑到的状态 $\\vec s$ ） 最后，当进行了10万盘棋后，在此状态选择那个分数最高的方案落子，此时，才真正下了这步棋。这种过程在论文里被称为Rollout 蒙特卡洛搜索树的方法十分的深刻精巧，充满的创造力，它有一些很有意思的特点： 没有任何人工决策的if else逻辑，完全依照规则本身，通过不断的想象（随机）来进行自我对弈，最后提升这一步的质量。有意思的是，其实这也是遵照了人类下棋的思维模式（模仿，只是这一次模仿的不是下棋风格，而是人类思考的方式。十分奇妙，人从飞鸟中受到启发发明了飞机，从鱼身上受到启发发明了潜艇，现在，机器学习的程序，通过学习人类使自身发生进化），人类中，水平越高的棋手，算的棋越多，只是人类对于每一个落子的判断能力更加强大，思考中的棋路，也比随机方式有效的多，但是机器胜在量大，暴力的覆盖到了很多情况。注意，这一个特点也为之后的提高提供了思路。 MCTS可是持续运行。这种算法在对手思考对策的时候自己也可以思考对策。在对方思考落子的过程中，MCTS也可以继续进行演算，在对面落子后，在用现在棋盘的情况进行演算，并且之前计算的结果一定可以用在现在情况中，因为对手的下的这步棋，很可能也在之前演算的高分落子选择内。这一点十分像人类 MCTS是完全可并行的算法 Aja Huang很快意识到这种方法的缺陷在哪里：初始策略（或者说随机的落子方式）太过简单。就如同上面第一条特点所说，人类对每种 $\\vec s$ （棋型）都要更强的判断能力，那么我们是否可以用 $P_{human}(\\vec s)$ 来代替随机呢？ Aja Huang改进了MCTS，每一步不使用随机，而是现根据 $P_{human}(\\vec s)​$ 计算得到 $\\vec a​$ 可能的概率分布，以这儿概率为准来挑选下一个 $\\vec a​$。一次棋局下完之后，新分数按照下面的方式来更新$$\\text{新分数} = \\text{调整后的初始分} + \\text{通过模拟的赢棋概率} \\tag{2-3}$$如果某一步被随机到很多次，就应该主要依据模拟得到的概率而非 $P_{human}(\\vec s)$ ，就是说当盘数不断的增加，模拟得到的结果可能会好于 $P_{human}(\\vec s)$ 得到的结果。所以 $P_{human}(\\vec s)$ 的初始分会被打个折扣，这也是公式2-3中的调整后的初始分的由来 $$ \\text{调整后的初始分} = \\frac{P_{human}(\\vec s)}{(\\text{被随机到的次数} + 1)} \\tag{2-4} $$ 如此一来，就在整张地图上利用 $P_{human}(\\vec s)$ 快速定位了比较好的落子方案，也增加了其他位置的概率。实际操作中发现，此方案不可行，因为计算这个 $P_{human}(\\vec s)$ 太慢了太慢了 一次 $P_{human}(\\vec s)$ 的计算需要3ms，随机算法1us，慢了3000倍，所以，Aja huang训练了一个简化版本的 $P_{human-fast}(\\vec s)$ ，把神经网络层数、输入特征减少，耗时下降到2us，基本满足了要求。 更多的，策略是，先以 $P_{human}(\\vec s)$ 开局，走前面大概20步，之后再使用 $P_{human-fast}(\\vec s)$ 走完剩下的到最后。兼顾速度和准确性。 综合了深度卷积神经网络和MCTS两种方案，此时的围棋程序已经可以战胜所有其他电脑，虽然和其他人类职业选手还有一定的差距。 2015年2月，Aja Huang在Deepmind的同事在顶级学术期刊nature上发表的文章 Human-level control through deep reinforcement learning 用神经网络打游戏。这篇文章，给AlphaGo提供的了新的方向 强化学习——局面函数（Value Network）强化学习（Reinforcement learning）用来实现左右互搏和自我进化，首先说说这篇论文干了一件什么事情，Deepmind团队的大牛们使用强化学习的方法在红白机上打通了200多个游戏，大多数得分都要比人好。 什么是强化学习那什么是强化学习呢？这里推荐莫烦大神的 什么是强化学习 系列教程的知乎专栏，以及另一篇强化学习指南 后者对强化学习的基本概念，实现方法进行全面的讲解，含有公式推导。还有两篇我自己做的笔记，什么是强化学习，强化学习算法介绍 对于强化学习（Reinforcement learning），它是机器学习的一个分支，特别善於控制一只能够在某个环境下自主行动的个体 (autonomous agent)，透过和环境之间的互动，例如 sensory perception 和 rewards，而不断改进它的 行为。 比如，吃豆人游戏，自主行动的个体就是控制的吃豆人，环境就是迷宫，奖励就是吃到的豆子，行为就是上下左右的操作。 强化学习的输入是 状态 (States) = 环境，例如迷宫的每一格是一个 state 动作 (Actions) = 在每个状态下，有什么行动是容许的 奖励 (Rewards) = 进入每个状态时，能带来正面或负面的 价值 (utility) 输出是 方案 (Policy) = 在每个状态下，你会选择哪个行动？也是一个函数 所以，我们需要根据S，A，R，来确定什么样的P是比较好的，通过不断的进行游戏，获得大量的交互数据，我们可以确定在每一个状态下，进行什么动作能获得最好的分数，而强化学习也就是利用神经网络来拟合这个过程。 例如，打砖块游戏有一个秘诀是把求打到墙后，这样球能自己反弹得分，强化学习程序在玩了600盘后，学到了这个秘诀。也就是说程序会在每一个状态下选择那个更容易把球打到墙后面去的操作。如下图，球快要把墙打穿的时候，评价函数 $v$ 的值会大幅度上升 打墙游戏的评价函数图 我们可以发现，强化学习的基本思路和MCTS后异曲同工之妙，也是在对游戏完全没有了解的情况，通过不断的训练（进行多盘对弈，和获得进行行动后的分数反馈）来进行训练，自我提升。 利用强化学习增强棋力参考这种思路，Aja Huang给围棋也设计了一个评价函数 $v(\\vec s)$ 。此函数的功能是：量化评估围棋局面。使用$v(\\vec s)$可以让我们在MCTS的过程中不用走完全局（走完全盘耗时耗力，效率不高）就发现已经必败。 在利用 $P_{human}(\\vec s)$ 走了开局的20步后，如果有一个 $v(\\vec s_i)$ （i为当前状态）可以直接判断是否能赢，得到最后的结果r，不需要搜索到底，可以从效率（剪枝，优化算法时间复杂度）上进一步增加MCTS的威力。 很可惜的，现有的人类棋谱不足以得出这个评价函数。所以Aja Huang决定用机器和机器对弈的方法来创造新的对局，也就是AlphaGo的左右互搏。 自对弈 神经网络的训练过程和结构 先用 $P_{human}(\\vec s)$ 和 $P_{human}(\\vec s)$ 对弈，比如1万盘，得到1万个新棋谱，加入到训练集中，训练出 $P_{human-1}(\\vec s)$ 。 使用$P_{human-1}(\\vec s)$和$P_{human-1}(\\vec s)$对弈，得到另1万个新棋谱，加入训练集，训练出$P_{human-2}(\\vec s)$。 同理，进行多次的类似训练，训练出$P_{human-n}(\\vec s)$，给最后的新策略命名为$P_{human-plus}(\\vec s)$ （感觉一下，这个$P_{human-plus}(\\vec s)$ 应该挺强力的！这里回顾一下$P_{human}(\\vec s)$是什么：是一个函数，$\\vec a=f(\\vec s)$ 可以计算出当前 $\\vec s$ 下的落子 $\\vec a$ 的分布概率） 使用$P_{human-plus}(\\vec s)$和$P_{human}(\\vec s)$进行对弈，发现$P_{human-plus}(\\vec s)$胜率80%，自对弈的方法被证明是有效的。（这里有一个想法，我在之前，一直加粗随机，之所以自对弈有效，就是因为整过MCTS过程中从来没有放弃过随机，如此一来，大量的计算，就更可能覆盖到更多的可能性，对提高棋力可以产生有效的作用同时。因为概率的问题，不断的自我对弈肯定造成下棋的路数集中，后面也会有体现） 但是事实并没有那么美好，Aja Huang发现，使用$P_{human-plus}(\\vec s)$来代替$P_{human}(\\vec s)$进行MCTS反而棋力会下降。 Aja Huang认为是$P_{human-plus}(\\vec s)$走棋的路数太集中，而MCTS需要更加发散的选择才能有更好的效果。 计算局部评价函数（Value Network）考虑到$P_{human-plus}(\\vec s)$的下法太过集中，Aja Huang计算 $v(\\vec s)$ 的策略是： 开局先用$P_{human}(\\vec s)$走L步，有利于生成更多局面 即使如此，Aja Huang还是觉得局面不够多样，为了进一步扩大搜索空间，在L+1步时，完全随机一个 $\\vec a$ 落子，记下这个状态 $v(\\vec s_{L+1})$ 之后使用$P_{human-plus}(\\vec s)$来进行对弈，直到结束时获得结果r，如此不断对弈，由于L也是一个随机数，我们可以得到，开局、中盘、官子等不同阶段的很多局面 $\\vec s$，和这些局面对应的结果r 有了这些训练样本 $\\langle \\vec s,r\\rangle$，还是使用神经网络，把最后一层改成回归而非分类（这里不是用的分类，而是用的回归，拟合），就得到了一个 $v(\\vec s)$ 来输出赢棋的概率 如上图所示，$v(\\vec s)$ 可以给出下一步落在棋盘上任意位置后，如果双方都用$P_{human-plus}(\\vec s)$来走棋，我方赢棋的概率。实验表明，仅仅使用$P_{human}(\\vec s)$来训练 $v(\\vec s)$ 效果不如$P_{human-plus}(\\vec s)$，强化学习是确实有效的。 总结，强化学习的$P_{human-plus}(\\vec s)$主要是用来获得 $v(\\vec s)$ 局部评估函数。表示的含义是 在状态 $\\vec s$ 下，局面的优劣程度，或者说此时的胜率是多少 $v(\\vec s)$ 局部评估函数拥有在线下不断自我进化的能力（这也是AlphaGo可以随时间越来越强的最重要的部分） 感谢你看到这里，我们已经拥有： $P_{human}(\\vec s)$ 我的老师是人类！ MCTS 乱下，我只看输赢 $v(\\vec s)$ 我能判断局势 有了这些我们距离AlphaGo已经不远了 AlphaGo MTCS流程图解 Aja Huang使用MCTS框架融合局面评估函数 $v(\\vec s)$ 的策略是： 使用$P_{human}(\\vec s)$作为初始分开局，每局选择分数最高的方案落子 到第L步后，改用$P_{human-fast}(\\vec s)$把剩下的棋局走完，同时调用 $v(\\vec s_L)$，评估局面的获胜概率，按照如下规则更新整个树的分数​$$\\text{新分数} = \\text{调整后的初始分} + 0.5*\\text{通过模拟得到的赢棋概率} + 0.5*\\text{局面评估分} \\tag {3-1}$$ 前两项和原来一样 如果待更新的节点就是叶子节点，局面评估分就是 $v(\\vec s_L)$ 如果是待更新的节点是上级节点，局面评估分是该叶子节点 $v(\\vec s)$ 的平均值 如果 $v(\\vec s)$ 是表示大局观，$P_{human-fast}(\\vec s)$表示快速演算，那么上面的方法就是二者的并重，并且Aja Huang团队已经用实验证明0.5 0.5的权重对阵其他权重有95%的胜率 详解AlphaGo VS 樊麾 对局走下某一步的计算过程 详解AlphaGo走某一步棋的过程1 a图使用局部评估函数计算出 $\\vec s$ 状态下其他落子点的胜率 b图MCTS中使用局部评估函数加 $P_{human}(\\vec s)$ 得出的结果 c图MCTS中使用$P_{human}(\\vec s)$（复合算法）和$P_{human-fast}(\\vec s)$走子走到底的结果 详解AlphaGo走某一步棋的过程2 d图深度卷积神经网络使用策略函数计算出来的结果 e图使用公式3-1和相关流程计算出的落子概率 f图演示了AlphaGo和樊麾对弈的计算过程，AlphaGo执黑，樊麾执白。红圈是AlphaGo实际落子额地方。1，2，3和后面的数字表示他想象中的之后樊麾下一步落子的地方。白色方框是樊麾的实际落子。在复盘时，樊麾认为1的走法更好（这说明在樊麾落子后AlphaGo也在进行计算） 总结由于状态数有限和不存在随机性，象棋和五子棋这类游戏理论上可以由终局自底向上的推算出每一个局面的胜负情况，从而得到最优策略。例如五子棋就被验证为先手必胜。 AlphaGo的MCTS属于启发式搜索算法 启发式搜索算法：由当前局面开始，尝试看起来可靠的行动，达到终局或一定步数后停止，根据后续局面的优劣反馈，选择最有行动。通俗来说，就是”手下一招子，心想三步棋“ 围棋是一个NP问题，要穷举的话，解空间巨大。现代优化算法的经典之处在于，从围棋的规则来看，在某一个状态，必定有一个或几个较优解，整个AlphaGo就是想方设法的去找这个较优解。利用局面评估函数来对MCTS进行剪枝的思路十分精彩。利用上面的3个算法，结合庞大的并行运算能力，还有Aja Huang团队的辛苦付出，造就了AlphaGo的奇迹。 使用不同组件AlphGo1.0的棋力 最终棋力结果 上图显示了各种算法的棋力，Rollout是走棋演算，也就是MCTS，Value Network是 $v(\\vec s)$ 局面评估函数，Policy Network 是结合$P_{human-plus}(\\vec s)$和$P_{human}(\\vec s)$后计算的策略函数（下一步走在哪里胜率高的深度卷积神经网络） 整个AlphaGo使用的技术，深度卷积网络，强化学习神经网络，都是炙手可热的领域，近年来发展迅猛，日新月异。AlphaGo已经完成了自己历史使命，借助棋类的巅峰【围棋】为叩门砖打开了机器学习自我进化的大门 李世石 VS AlphaGo 1.0——第四局78手挖 赛后AlphaGo之父给出的关键信息：李世石78手“挖”是AlphaGo认为概率极小的点，这一手之后导致的状态 $\\vec s$ 进入到了AlphaGo能处理的范围之外，即之前AlphaGo的自对弈都是建立用自己觉得好的下法来搜索的，那么如果这一手AlphaGo1.0感觉可能性极小，那么用$P_{human}(\\vec s)$自对弈的棋谱中就更加难以覆盖。 但是也需要提到的是，根据比赛中柯洁等人的观战我们知道，如果不是后面AlphaGo进入了混乱模式，78手不一定是一个好棋。只能说这一手，顶到了AlphaGo的软肋，在真正和人的对局中不一定是“神之一手” 根据Deepmind团队给出的数据可以知道，一年前，AphaGo1.0的搜索空间，自对弈深度并不完美。所以Deepmind团队有意的在代码逻辑上让其避免打劫，或者说避免劫争，例如，有两个选择，一个胜率60%但需要打劫，另一个55%但不需要打劫，AlphaGo1.0会选择后者。 那么什么是打劫呢？解释这几个和”劫“有关的围棋术语是： 打劫围棋术语，一方制造事端，和另一方讨价还价的行为。劫材可以用来做价格谈判的筹码。通常是走一手没戏，但对手若不予置理，再走第二手会出棋的局部。寻劫通过目数计算，寻找一些有价值的局部制造事端强迫对手应答。通常价值至少需要和打劫的地方相当或者小不太多，否则对方很容易消劫。利用劫劫胜可杀死对方或者得到利益，劫败也应该让对方付出代价，除非双方劫材大小和数量相差悬殊。 通俗的说是，我在这一片已经处于劣势，我换一个战场，发动进攻，你应不应？可能在另外战场的角力中对这边战场的局势产生影响。可以类比于，五子棋中的冲四。 如果有人观看了这一盘棋，我们也可以听到柯洁在强调，AlphaGo在避免打劫，出现了几手莫名其妙的落子。 总结来说，AlphaGo依靠的是对局外的大量计算，无论是局部评估函数，还是$P_{human-plus}(\\vec s)$都十分依赖对局外的大量的计算。随着时间的推移，AlphaGo在对局过程需要的时间越来越固定，不需要在对局时进行太多的MCTS搜索就能获得AlphaGo的下一手位置，可以预见，MCTS的搜索深度不会太深。当计算量十分庞大的时候，依赖更多是那个120层的Policy Network。 从柯洁的第二盘可以发现，他已经努力的制造在中腹引入多方战斗的带劫争的复杂棋局，十分精彩。可惜，AlphaGo2.0貌似已经完善了自己的阿特留斯之踵。当真无敌，说到这里，我们来谈谈AlphaGo2.0 AlphaGo 2.0 VS 柯洁——虽败犹荣三盘对局，感觉到AlphaGo在这一年内进行了极为深度的训练。最可怕的是AlphaGo通过时间验证了机器学习对于解决NP问题的强大潜力（通过这三盘可以看出已经无限接近解决了这个问题，至少在对人类上）。甚至： 臆想一，是否可以利用AlphaGo来判断规则是否公平（中国和韩日规则的不同，7目半和6目半）。 臆想二，最终AlphaGo的自对弈是接近和棋。可惜AlphaGo已经退役。希望针对Deepmind放出的50盘自对弈棋谱可以研究出一些门道，使得围棋这门竞技本身有更大的突破。 局面函数和策略函数愈发强大，愈加的接近于”围棋之神“。 随着Google TPU的发布，跑在TPU阵列上的AlphaGo如虎添翼，MCTS的走子演算效率更高，速度更快（加速的其实就是$P_{human-plus}(\\vec s)$的落子速度。 关于TPU的设计思路和原理可以参考 In-Datacenter Performance Analysis of a Tensor Processor 对于围棋这个策略单步游戏，是存在N步最优解（不存在i+1步最优解），AlphaGo已经在正确的道路上无限的接近于这个N步最优解，仿佛在某一步已经看到了你无论怎么下都能走到的N步最优解。 人类的每一次失误都会使局部评估函数往胜率移动一点，这一点是十分可怕的，因为算法本身的优越性，大局观对于AlphaGo的逻辑来说本身就是一种刻在骨子里的基因 一是因为AlphaGo每次MCTS计算都会计算到接近分出胜负，具有前瞻性 二是因为局面函数本身就是为了来统计大局形势定义的，具有判断局面优劣的能力 所谓大局观，不就是这种走一步看N步的能力嘛。 对未来的展望——从AlphaGo想开去珍贵的并不是攻克了围棋问题本身，而是这种解决问题的基本模式，可以推而广之到很多领域。 先通过卷积网络学习人类的下法，算出策略函数（Policy Network），再通过模仿进行强化学习，左右互搏，不断自我进化，再加上MCTS的经典的解决问题的启发式搜索算法。 这俨然是一个 模仿➜学习➜优化的过程 或许，模仿人类，是机器学习最终的归途，至于应用领域方面 游戏AI是一个最容易想到的领域，只要能抽象出 State Action Judgement，那么这一套解决问题的方式就可以举一反三，让每一个1V1领域的游戏AI非常强大（OpenAI在Dota2 1V1 Solo上的结果更加证明了这一点），至于合作领域的AI可能需要更大的计算量去计算（OpenAI发布的论文MultiAgent很有启发性），对于实际问题来说获得这样的AI有多大的经济价值值得推敲。 游戏的乐趣就在于不确定性，适当的失误也是竞技类游戏的魅力所在，一个能看到N步最优解的AI会让一个游戏机制，游戏规则变得可数据化，这一点其实是游戏被创造出来的初衷相背离的。 其他方面，只要是人类可以学习出来的事物，比如翻译，编程，都是现在的这套体系可能解决的问题，我们期待未来这套解决问题的方法发挥出无穷的力量吧！ [Reference]知乎Tao Lei大神的回答知乎袁行远大神的回答知乎有关围棋打劫的回答其他文章中引用的论文，链接已经给出","tags":[{"name":"AlphaGo","slug":"AlphaGo","permalink":"https://charlesliuyx.github.io/tags/AlphaGo/"},{"name":"CNN","slug":"CNN","permalink":"https://charlesliuyx.github.io/tags/CNN/"},{"name":"MCTS","slug":"MCTS","permalink":"https://charlesliuyx.github.io/tags/MCTS/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://charlesliuyx.github.io/tags/Deep-Learning/"}]},{"title":"清欢 - 林清玄","date":"2017-05-14T16:26:55.000Z","path":"2017/05/14/清欢/","text":"1少年时代读到苏轼的一阕词，非常喜欢，到现在还能背诵： 细雨斜风作晓寒，淡烟疏柳媚晴滩，入淮清洛渐漫漫。 雪沫乳花浮午盏，蓼茸蒿笋试春盘，人间有味是清欢。 这阕词，苏轼在旁边写着“元丰七年十二月二十四日，从泗州刘倩叔游南山”，原来是苏轼和朋友到郊外去玩，在南山里喝了浮着雪沫乳花的淡茶，配着春日山野里的蓼菜、茼蒿、新笋，以及野草的嫩芽等等，然后自己赞叹着：“人间有味是清欢！” 当时所以能深记这阕词，最主要的是爱极了后面这一句，因为试吃野菜的这种平凡的清欢，才使人间更有滋味。“清欢”是什么呢？清欢几乎是难以翻译的，可以说是“清淡的欢愉”，这种清淡的欢愉不是来自别处，正是来自对平静疏淡简朴生活的一种热爱。当一个人可以品味出野菜的清香胜过了山珍海味，或者一个人在路边的石头里看出了比钻石更引人的滋味，或者一个人听林间鸟鸣的声音感受到比提笼遛鸟更感动，或者体会了静静品一壶乌龙茶比起在喧闹的晚宴中更能清洗心灵……这些就是“清欢”。 清欢之所以好，是因为它对生活的无求，是它不讲求物质的条件，只讲究心灵的品味。“清欢”的境界很高，它不同于李白的人生在世不称意，明朝散发弄扁舟那样的自我放逐；或者人生得意须尽欢，莫使金樽空对月那种尽情的欢乐。它也不同于杜甫的人生有情泪沾臆，江水江花岂终极这样悲痛的心事，或者人生不相见，动如参与商；今夕复何夕，共此灯烛光那种无奈的感叹。 活在这个世界上，有千百种人生，文天祥的是人生自古谁无死，留取丹心照汗青，我们很容易体会到他的壮怀激烈。欧阳修的是人生自是有情痴，此恨不关风与月，我们很能体会到他的绵绵情恨。纳兰性德的是人到情多情转薄，而今真个不多情，我们也不难会意到他无奈的哀伤。甚至于像王国维的人生只似风前絮，欢也零星，悲也零星，都作连江点点萍！那种对人生无常所发出的刻骨的感触，也依然能够知悉。 2可是“清欢”就难了！ 尤其是生活在现代的人，差不多是没有清欢的。 什么样是清欢呢？我们想在路边好好的散个步，可是人声车声不断的呼吼而过，一天里，几乎没有纯然安静的一刻。 我们到馆子里，想要吃一些清淡的小菜，几乎是杳不可得，过多的油、过多的酱、过多的盐和味精已经成为中国菜最大的特色，有时害怕了那样的油腻，特别嘱咐厨子白煮一个菜，菜端出来时让人吓一跳，因为菜上挤的色拉比菜还多。 有时没有什么事，心情上只适合和朋友去啜一盅茶、饮一杯咖啡，可惜的是，心情也有了，朋友也有了，就是找不到地方，有茶有咖啡的地方总是嘈杂的。 俗世里没有清欢了，那么到山里去吧！到海边去吧！但是，山边和海湄也不纯净了，凡是人的足迹可以到的地方，就有了垃圾，就有了臭秽，就有了吵闹！ 有几个地方我以前常去的，像阳明山的白云山庄，叫一壶兰花茶，俯望着台北盆地里堆叠着的高楼与人欲，自己饮着茶，可以品到茶中有清欢。像在北投和阳明山间的山路边有一个小湖，湖畔有小贩卖工夫茶，小小的茶几、藤制的躺椅，独自开车去，走过石板的小路，叫一壶茶，在躺椅上静静的靠着，有时湖中的荷花开了，真是惊艳一山的沉默。有一次和朋友去，在躺椅上静静喝茶，一下午竟说不到几句话，那时我想，这大概是“人间有味是清欢”了。 现在这两个地方也不能去了，去了只有伤心。湖里的不是荷花了，是飘荡着的汽水罐子，池畔也无法静静躺着，因为人比草多，石板也被踏损了。到假日的时候，走路都很难不和别人推挤，更别说坐下来喝口茶，如果运气更坏，会遇到呼啸而过的飞车党，还有带伴唱机来跳舞的青年，那时所有的感官全部电路走火，不要说清欢，连欢也不剩了。 要找清欢，一日比一日更困难了。 当学生的时候，有一位朋友住在中和圆通寺的山下，我常常坐着颠踬的公交车去找她，两个人沿着上山的石阶，漫无速度的，走走、坐坐、停停、看看，那时圆通寺山道石阶的两旁，杂乱的长着朱槿花，我们一路走，顺手拈下一朵熟透的朱槿花，吸着花朵底部的花露，其甜如蜜，而清香胜蜜，轻轻的含着一朵花的滋味，心里遂有一种只有春天才会有的欢愉。 3圆通寺是一座全由坚固的石头砌成的寺院，那些黑而坚强的石头坐在山里仿佛一座不朽的城堡，绿树掩映，清风徐徐，站在用石板铺成的前院里，看着正在生长的小市镇，那时的寺院是澄明而安静的，让人感觉走了那样高的山路，能在那平台上看着远方，就是人生里的清欢了。 后来，朋友嫁人，到国外去了。我去过一趟圆通寺，山道已经开辟出来，车子可以环山而上，小山路已经很少人走，就在寺院的门口摆着满满的摊贩，有一摊是儿童乘坐的机器马，叽哩咕噜的童歌震撼半山，有两摊是打香肠的摊子，烤烘香肠的白烟正往那古寺的大佛飘去，有一位母亲因为不准孩子吃香肠而揍打着两个孩子，激烈的哭声尖亢而急促……我连圆通寺的寺门都没有进去，就沉默的转身离开，山还是原来的山，寺还是原来的寺，为什么感觉完全不同了，失去了什么吗？失去的正是清欢。 下山时的心情是不堪的，想到星散的朋友，心情也不是悲伤，只是惆怅，浮起的是一阕词和一首诗，词是李煜的：高楼谁与上？长记秋晴望。往事已成空，还如一梦中！诗是李觏的：人言落日是天涯，望极天涯不见家；已恨碧山相阻隔，碧山还被暮云遮！那时正是黄昏，在都市烟尘蒙蔽了的落日中，真的看到了一种悲剧似的橙色。 我二十岁心情很坏的时候，就跑到青年公园对面的骑马场去骑马，那些马虽然因驯服而动作缓慢，却都年轻高大，有着光滑的毛色。双腿用力一夹，它也会如箭一般呼噜向前窜去，急忙的风声就从两耳掠过，我最记得的是马跑的时候，迅速移动着的草的青色，青茸茸的，仿佛饱含生命的汁液，跑了几圈下来，一切恶的心情也就在风中、在绿草里、在马的呼啸中消散了。 尤其是冬日的早晨，勒着绳，马就立在当地，踢踏着长腿，鼻孔中冒着一缕缕的白气，那些气可以久久不散，当马的气息在空气中消弭的时候，人也好像得到某些舒放了。 骑完马，到青年公园去散步，走到成行的树荫下，冷而强悍的空气在林间流荡，可以放纵的、深深的呼吸，品味着空气里所含的元素，那元素不是别的，正是清欢。 4最近有一天，突然想到骑马，已经有十几年没骑了。到青年公园的骑马场时差一点吓昏，原来偌大的马场已经没有一根草了，一根草也没有的马场大概只有台湾才有，马跑起来的时候，灰尘滚滚，弥漫在空气里的尽是令人窒息的黄土，蒙蔽了人的眼睛。马也老了，毛色斑剥而失去光泽。 最可怕的是，不知道什么时候在马场搭了一个塑料棚子，铺了水泥地，其丑无比，里面则摆满了机器的小马，让人骑用，其吵无比。为什么为了些微的小利，而牺牲了这个马场呢？ 马会老是我知道的事，人会转变是我知道的事，而在有真马的地方放机器马，在马跑的地方没有一株草，则是我不能理解的事。 就在马场对面的青年公园，已经不能说是公园了，人比西门町还拥挤吵闹，空气比咖啡馆还坏，树也萎了，草也黄了，阳光也不灿烂了。从公园穿越过去，想到少年时代的这个公园，心痛如绞，别说清欢了，简直像极了佛经所说的“五浊恶世”！ 生在这个时代，为何“清欢”如此难觅。眼要清欢，找不到青山绿水；耳要清欢，找不到宁静和谐；鼻要清欢，找不到干净空气；舌要清欢，找不到蓼茸蒿笋；身要清欢，找不到清凉净土；意要清欢，找不到智慧明心。如果要享受清欢，唯一的方法是守在自己小小的天地，洗涤自己的心灵，因为在我们拥有愈多的物质世界，我们的清淡的欢愉就日渐失去了。 现代人的欢乐，是到油烟爆起、卫生堪虑的啤酒屋去吃炒蟋蟀；是到黑天暗地、不见天日的卡拉OK去乱唱一气；是到乡村野店、胡乱搭成的土鸡山庄去豪饮一番；以及到狭小的房间里做方城之戏，永远重复着摸牌的一个动作……这些放逸的生活以为是欢乐，想起来毋宁是可悲的。为什么现代人不能过清欢的生活，反而以浊为欢，以清为苦呢？ 一个人以浊为欢的时候，就很难体会到生命清明的滋味，而在欢乐已尽、浊心再起的时候，人间就愈来愈无味了。 5这使我想起东坡的另一首诗来： 梨花淡白柳深青，柳絮飞时花满城； 惆怅东栏一株雪，人生看得几清明？ 苏轼凭着东栏看着栏杆外的梨花，满城都飞着柳絮时，梨花也开了遍地，东栏的那株梨花却从深青的柳树间伸了出来，仿佛雪一样的清丽，有一种惆怅之美，但是人生看这么清明可喜的梨花能有几回呢？这正是千古风流人物的性情，这正是清朝大画家盛大士在《溪山卧游录》中说的凡人多熟一分世故，即多一分机智。多一分机智，即少却一分高雅。 也有说山中何所有？岭上多白云，只可自怡悦，不堪持赠君，自是第一流人物。 第一流人物是什么人物？ 第一流人物是在清欢里也能体会人间有味的人物！ 第一流人物是在污浊滔滔的人间，也能找到清欢的人物！","tags":[{"name":"随笔","slug":"随笔","permalink":"https://charlesliuyx.github.io/tags/随笔/"}]},{"title":"English-abbreviation","date":"2017-05-14T00:29:00.000Z","path":"2017/05/13/English-abbreviation/","text":"一些常用的英语缩写的总结 日常生活篇 R.S.V.P: 源自于法语‘Répondez s’il vous plait’，英文解释为’Respond,if you please’.邀请函结尾写这个，表示‘敬请回复’； P.S: 意思是‘post script’,表示‘再多说一句’，一般写完要说的话之后结尾突然想起说什么可以写； ASAP: as soon as possible. 表示‘尽快’，注意听音频发音，可读成A-SAP; ETA: estimated time of arrival. 表示‘预计到达时间’； BYOB: bring your own bottle; 表示‘自带酒水，举办派对时常用’ 吃饭做菜篇 tsp or t : teaspoon 一茶匙 tbs / tbsp/ T: tablespoon 一汤匙 c: cup 一杯 gal: gallon 加仑 lb : pound 磅 pt：pint 品脱 qt: quart 夸脱 出国地图篇 Ave: avenue 大街 Blvd: boulevard 大道 Ln: lane 车道 Rd: road 公路 St: street 街道 教育工作篇 BA: Bachelor of Arts 文学士 BS: Bachelor of Science 理学士 MA: Master of Arts 文科硕士 PA: Personal Assistant 私人助理 VP: Vice President 副总统;副总裁 CEO: Chief Executive Officer 首席执行官 CFO: Chief Financial Officer 首席财务官 COO: Chief Operating Officer 首席运营官 CMO: Chief Marketing Officer 首席营销官 社交聊天篇 JK :just kidding 跟你开玩笑呢 TBD: to be determined 待定 AFAIK: as far as I know 据我所知 BRB: be right back 马上回来 CUL: see you later 回见 TTYL: talk to you later 回聊 CWYL: chat with you later 回聊 LOL: laugh out loud 哈哈 LMAO: laugh my ass off 笑死我了 ROTFL/ ROFL: rolling on the floor laughing 笑到在地上打滚 NP: no problem 没问题,没关系,不客气 IDK: I don’t know 我不知道 ILY: I love you 我爱你 TMI: too much information 信息量太大了； 说的太多了 OIC: Oh, I see. 我明白了 FYI: for your information 顺便告知你 BTW: by the way 顺便说一下 顺便问一下 MYOB: mind your own business 别多管闲事 FAQ: frequently asked questions 经常被问的问题20: WTF: what the fuck 搞毛阿…… 委婉的是WTH: what the hell/heck21: AKA: also known as. 也叫做 TGIF: thank god It’s Friday 谢天谢地又到礼拜五了 TBC: to be continued; to be confirmed 未完待续/ 有待确认 数字字母篇2: to/too4: forB: beC: seeI: eyeO: owe;R: are;U: you;ur: your/you’reY: why","tags":[{"name":"英语积累","slug":"英语积累","permalink":"https://charlesliuyx.github.io/tags/英语积累/"}]},{"title":"有关中国诗的那些事","date":"2017-05-13T23:40:00.000Z","path":"2017/05/13/有关中国诗的那些事/","text":"没有沉淀，文字永远上不了档次。难得空闲，读了些诗，有些感受。 韦应物 独怜幽草涧边生，上有黄鹂深树鸣。春潮带雨晚来急，野渡无人舟自横。 记起这《滁州西涧》，听过一个故事。话说一次国画比赛，题目是以春潮带雨晚来急，野渡无人舟自横这句诗作画。国学博大精深，国画作为其中一支配起诗来，别有遐想。此题甚好，不仅考及画技，更有对国学中诗词的体悟和见解。大家不妨也想想如果是你，你会怎么画？这里先卖个关子。 从诗的字面来说，是这样一种通感：春天近了，潮气依稀可嗅。但谁能像你这样，对一棵在水边生长的小草也充满爱怜？黄鹂在密林深处的低语你都能听到？这需要多么细腻的一颗心。华灯初上，渡口上已经没有人，舟独自横于水上，那是一种空阔的感觉。映照你一生步履，你的细腻出于岁月。你当年49岁，50载，可能不长，但是我知道你的与众不同，你的50载甚至顶得别人几辈子。 韦应物年少荒唐，并未认真读书。安史乱起，韦应物扈从不及，流落秦中。乱后，韦应物折节读书，痛改前非，从一个富贵无赖纨绔一变而为忠厚仁爱的儒者。有些官运，在地方（苏州）任官。韦应物勤于吏职，简政爱民，在苏州刺史届满之后，一贫如洗，寄居无定寺，客死他乡。 享年五十五岁。 别人些许看出的是你不在其位，不得其用的无奈，忧伤。但我看到的，更多是你的豁达，你心中总是美好多于忧伤。 通往远方的路，没有哪条是你不能走的；走在路上的人，没有谁是你不能结交的；结交的朋友，没有谁是你不能推心置腹的。虽然那个时代远没有现在的复杂，但是能捧出一颗完整的心也并不是一件容易的事。韦苏州，你是一个充满诗情的人。 回头看看开头提到的国画比赛优胜者的作品：弥蒙的雾气用模糊的淡墨衬托，远处的群山，夕阳露出半个头。远远的有几簇灯火，近处，一条小舟在几根芦苇中飘荡，船上有位着布衣的蓑翁，嘴里叼根芦苇，帽檐下压，不知是否在闭目养神，两只杜鹃立于船头。起初不懂，“无人”的野渡为何有人呢？其中深意，结合了韦苏州的履历才恍然大悟。 “无人”并不是一只孤舟。韦应物闲居，船上舟子，好似当时的韦应物，在船头打盹，闻着草香，听着鹂鸣。韦应物虽然赋闲苏州，但他并不排斥官场，若有机会，他还是会出仕，只是满足于闲暇。无奈忧伤可能有，但经历了顽劣，奋起，战乱，官场，贬谪，闲居的韦应物，更多的，是看破人生的豁达和满足。 李白总觉中国诗总离不开一个“愁”字。思乡，思亲，忧国，羁旅等等，都和“愁”万缕千丝。我爱这些无奈，悲壮，不舍，甚至愤懑，嘲讽。他们仿佛缩影了人生，视角令人称奇，细腻的令你悸动。 抽刀断水，是最无奈的神话；举杯消愁，是最动情的悲歌。李白潇洒一生，他豪放，甚至一直清贫，有了几个钱，就豪饮一番，将诗情挥洒，更是对“愁”下了如此入理的定义。 拣尽寒枝不肯栖，寂寞沙洲岭李白就犹如谪仙，似乎从来没有受过来自这个世界的温暖。于是，在静夜里，李白写下了床前明月光，疑是地上霜。举头望明月，低头思故乡的千古“愁”词。可是李白的故乡在哪里呢？是陇西？是巴蜀？月华似霜的夜，浪迹天涯的游子李白在梦幻中寻觅故乡，但故乡却比梦幻更飘渺。 李白是复杂的，李白糅合着道家的“出世”和儒家的“入世”思想。所以，顺境时，他仰天大笑出门去，我辈岂是蓬蒿人的潇洒豪情；逆境时，他有弃我去者昨日之日不可留，乱我心者今日之日多烦忧的绵绵愁绪。 那些诗人感动于张谓笔下早梅傲雪不知近水花先发，疑是经冬雪未消的玄妙；陶醉于贺铸风中一川烟草，满城风絮，梅子黄时雨的飘愁；哀婉于苏轼眼中细看来，不是杨花，点点是，离人泪的破碎。 说起苏东坡，一个传奇。 人生如梦，东坡曾经迷惘过；早生华发，东坡曾经惋惜过；十年生死两茫茫，东坡曾经痛苦过。但他不屈，他平和，他豁达。 一蓑烟雨任平生，他淡泊；日啖荔枝三百颗，不辞长作岭南人，他自定；踏雪飞鸿，他淡然。问汝平生功业，黄州惠州儋州，三贬之地，还恰恰就是他留下许多不朽之作的地方。 读着这些诗，深深思索，你会感到作为一个中国人学会了中文，有着五千年的浩瀚历史文化，是多么令你振奋和自豪；国学，遗留的东西，值得我们用一生去参悟。常说高考诗词理解令人头痛，如果怀着这样的心情读诗，你还会怕吗？","tags":[{"name":"随笔","slug":"随笔","permalink":"https://charlesliuyx.github.io/tags/随笔/"}]}]